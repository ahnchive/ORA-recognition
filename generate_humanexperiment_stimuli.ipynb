{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1a2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization_original import *\n",
    "from rrcapsnet_original import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "N_MINI_PER_CORRUPTION = 1000\n",
    "\n",
    "# general helper funtions for model testing\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "def test_model(task, model, args, verbose=False):\n",
    "    # set task and print setting\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    \n",
    "    # get test results\n",
    "    model.eval()\n",
    "    test_dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train=False)\n",
    "    test_loss, test_loss_class, test_loss_recon, test_acc = test(model, test_dataloader, args, acc_name=\"dynamic\")\n",
    "    if verbose:\n",
    "        print(\"==> test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (test_loss, test_loss_class, test_loss_recon, test_acc))\n",
    "    return test_loss, test_loss_class, test_loss_recon, test_acc\n",
    "\n",
    "# helper funtions for model testing on mnist-C\n",
    "def test_model_mnistc(path_mnistc, corruptionlist, model, verbose=False):\n",
    "    # set task and print setting\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    \n",
    "    # get average test results over corruptionlist   \n",
    "    losses, classlosses, reconlosses, accs = [], [], [], []\n",
    "    for corruption in corruptionlist:\n",
    "        test_loss, test_loss_class, test_loss_recon, test_acc = test_model_on_each_corruption(path_mnistc, corruption, model, verbose)\n",
    "\n",
    "        losses.append(test_loss)\n",
    "        classlosses.append(test_loss_class)\n",
    "        reconlosses.append(test_loss_recon)\n",
    "        accs.append(test_acc)\n",
    "    \n",
    "    avgtest_loss = sum(losses)/len(corruptionlist)\n",
    "    avgtest_loss_class = sum(classlosses)/len(corruptionlist)\n",
    "    avgtest_loss_recon = sum(reconlosses)/len(corruptionlist)\n",
    "    avgtest_acc = sum(accs)/len(corruptionlist)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"==> average test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (avgtest_loss, avgtest_loss_class, avgtest_loss_recon, avgtest_acc))\n",
    "        \n",
    "    return avgtest_loss, avgtest_loss_class, avgtest_loss_recon, avgtest_acc\n",
    "    \n",
    "def test_model_on_each_corruption(path_mnistc, corruption, model, verbose=False):\n",
    "    path_images = os.path.join(path_mnistc, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(path_mnistc, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # test on the dataloder\n",
    "    model.eval()\n",
    "    test_loss, test_loss_class, test_loss_recon, test_acc = test(model, dataloader, args, acc_name=\"dynamic\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"==> individual test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (test_loss, test_loss_class, test_loss_recon, test_acc))\n",
    "    return test_loss, test_loss_class, test_loss_recon, test_acc\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_batch(task, batchnum, model, args, train=False, verbose=True, onlyacc=False):\n",
    "    \n",
    "    # evaluate on one train/test batch \n",
    "    model.eval()\n",
    "    \n",
    "    if task == 'mnist_recon':\n",
    "        # for mnist recon data, it has erased input(x) and intact input (gtx)\n",
    "        if train:\n",
    "            dataloader, val_dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train)\n",
    "        else:\n",
    "            dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train)            \n",
    "        diter = iter(dataloader)\n",
    "        for i in range(batchnum):\n",
    "            x, gtx, y = next(diter)\n",
    "    else:\n",
    "        dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train)    \n",
    "        diter = iter(dataloader)\n",
    "        for i in range(batchnum):\n",
    "            x, y = next(diter)\n",
    "            gtx = None\n",
    "            \n",
    "            \n",
    "    # attach forward hooks for intermediate outputs for visualizations\n",
    "    outputs = {}\n",
    "    \n",
    "    # from model main output\n",
    "    x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "#     affine_params_step=[]\n",
    "    \n",
    "    # from model dynamic routing\n",
    "    coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "    outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "    def get_attention_outputs():\n",
    "        def hook(model, input, output):\n",
    "            x_mask_step.append(output[0].detach())\n",
    "            x_input_step.append(output[1].detach())\n",
    "        return hook\n",
    "\n",
    "    def get_capsule_outputs():\n",
    "        def hook(model, input, output):\n",
    "            objcaps_step.append(output[0].detach())\n",
    "            coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "            betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "            if 'rscores' in output[1].keys():\n",
    "                rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "            if 'recon_coups' in output[1].keys():\n",
    "                recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "            if 'outcaps_len' in output[1].keys():\n",
    "                outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "            if 'outcaps_len_before' in output[1].keys():\n",
    "                outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "        return hook\n",
    "    \n",
    "\n",
    "    hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "    hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "    \n",
    "    # evaluate and detach hooks\n",
    "    losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_name='dynamic', gtx=gtx)\n",
    "    hook1.remove()\n",
    "    hook2.remove()\n",
    "    \n",
    "    # add tensor outputs dictionary\n",
    "    outputs['x_input'] = torch.stack(x_input_step, dim=1)\n",
    "    outputs['x_mask'] = torch.stack(x_mask_step, dim=1)\n",
    "    outputs['objcaps'] = torch.stack(objcaps_step, dim=1)\n",
    "    \n",
    "    outputs['coups'] = torch.stack(coups_step, dim=1)\n",
    "    outputs['betas'] = torch.stack(betas_step, dim=1)\n",
    "    if rscores_step:\n",
    "        outputs['rscores'] = torch.stack(rscores_step, dim=1)\n",
    "    if recon_coups_step:\n",
    "        outputs['recon_coups'] = torch.stack(recon_coups_step, dim=1)\n",
    "    if outcaps_len_step:\n",
    "        outputs['outcaps_len'] = torch.stack(outcaps_len_step, dim=1)\n",
    "    if outcaps_len_before_step:\n",
    "        outputs['outcaps_len_before'] = torch.stack(outcaps_len_before_step, dim=1)        \n",
    "    if verbose:\n",
    "        print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (losses[0], losses[1], losses[2], acc))\n",
    "    \n",
    "    if onlyacc:\n",
    "        return acc\n",
    "    else:\n",
    "        return x, gtx, y, objcaps_len_step, x_recon_step, outputs\n",
    "    \n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_mini(corruption, model, args, train=False, verbose=True, save_hooks=False, max_batch_num=None):\n",
    "    \n",
    "    # get corruption batch information\n",
    "    corruption_id = int(CORRUPTION_TYPES.index(corruption))\n",
    "    num_batch_required = int(N_MINI_PER_CORRUPTION/BATCHSIZE) # if batchsize 100; 10 batches are requried\n",
    "    \n",
    "    # load dataloader and iterator\n",
    "    dataloader = fetch_dataloader('mnist_c_mini', DATA_DIR, DEVICE, BATCHSIZE, train)    \n",
    "    diter = iter(dataloader)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "    model.eval()        \n",
    "    # get input and gt\n",
    "    for i in range(corruption_id*num_batch_required): #id =0, 0 iteration; id=1, 10 iteration\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "    \n",
    "    for i in range(0, num_batch_required):\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "            \n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_name='dynamic', gtx=gtx)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "            \n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "        \n",
    "        if save_hooks:\n",
    "        \n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_mini(corruption, cnn, max_batch_num=None):\n",
    "    # get corruption batch information\n",
    "    corruption_id = int(CORRUPTION_TYPES.index(corruption))\n",
    "    num_batch_required = int(N_MINI_PER_CORRUPTION/BATCHSIZE) # if batchsize 100; 10 batches are requried\n",
    "    \n",
    "    # load dataloader and iterator\n",
    "    dataloader = fetch_dataloader('mnist_c_mini', DATA_DIR, DEVICE, BATCHSIZE, train=False)    \n",
    "    diter = iter(dataloader)\n",
    "    \n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "    cnn.eval() \n",
    "\n",
    "    # get input and gt\n",
    "    for i in range(corruption_id*num_batch_required): #id =0, 0 iteration; id=1, 10 iteration\n",
    "        x, y = next(diter)\n",
    "    \n",
    "\n",
    "    for i in range(0, num_batch_required):\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "        \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "        \n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "    \n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "    \n",
    "    model.eval()        \n",
    "    # get input and gt\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "                    \n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_name='dynamic', gtx=gtx)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "            \n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "        \n",
    "        if save_hooks:\n",
    "        \n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_original(corruption, cnn):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "    cnn.eval() \n",
    "\n",
    "    # get input and gt\n",
    "\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "        \n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "    \n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "\n",
    "def save_imgarr(imgarr, filename='test.png', scale=8):\n",
    "    h, w, _ = imgarr.shape\n",
    "    fig, axes = plt.subplots(figsize=(h*scale, w*scale))\n",
    "    fig.subplots_adjust(top=1.0, bottom=0, right=1.0, left=0, hspace=0, wspace=0) \n",
    "    axes.imshow(imgarr, cmap='gray_r')\n",
    "    axes.axis('off')\n",
    "    plt.savefig(filename, dpi=1, format='png') \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50981e4b",
   "metadata": {},
   "source": [
    "# experiment 1: timestep vs RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3fb5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 4\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "original is used\n",
      "==> corruption type: spatter, this batch acc: 0.9830999970436096\n",
      "correct:  9831\n",
      "incorrect:  169\n",
      "step2:  9768\n",
      "step3:  59\n",
      "step4:  4\n",
      "all images are saved\n",
      "original is used\n",
      "==> corruption type: zigzag, this batch acc: 0.9555999636650085\n",
      "correct:  9556\n",
      "incorrect:  444\n",
      "step2:  9406\n",
      "step3:  132\n",
      "step4:  18\n",
      "all images are saved\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "#############################\n",
    "# test a single model, and visualize outputs\n",
    "#############################\n",
    "task='mnist_c_original'\n",
    "# task='mnist_c_original'\n",
    "# task='mnist_recon'\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "\n",
    "# load model\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 4, 'routings': 3,'mask_threshold': 0.1}\n",
    "\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt'\n",
    "\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "path_save = './stimuli/stimuli-exp1-step4/'\n",
    "#  obtain model prediction\n",
    "\n",
    "d_triallist = {}\n",
    "\n",
    "for corruption_index in [13, 15]:\n",
    "\n",
    "    corruption =CORRUPTION_TYPES[corruption_index-1]\n",
    "    \n",
    "    d_triallist[corruption] = {}\n",
    "    \n",
    "    if task == 'mnist_c_mini':\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step, outputs_model  = \\\n",
    "        evaluate_model_on_mnistc_mini(corruption, model, args, train, verbose=False, save_hooks=True, max_batch_num=None)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    elif task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "        evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    else:\n",
    "        batchnum=3*int(1000/BATCHSIZE)-1\n",
    "        x, gtx, y, objcaps_len_step, x_recon_step, outputs = evaluate_on_batch(task, batchnum, model, args, train)\n",
    "\n",
    "    # get model prediction\n",
    "    objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "    # pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "\n",
    "    def get_nstep(objcaps_len_step_narrow, y_hot):\n",
    "        def get_first_zero_index(x, axis=1):\n",
    "            cond = (x == 0)\n",
    "            return ((cond.cumsum(axis) == 1) & cond).max(axis, keepdim=True)[1]\n",
    "\n",
    "        pstep = objcaps_len_step_narrow.max(dim=-1)[1]\n",
    "        pnow = pstep[:,1:]\n",
    "        pbefore = pstep[:,:-1]\n",
    "\n",
    "        pdiff = (pnow-pbefore)\n",
    "        null_column = -99*torch.ones(pdiff.size(0),1).to(pdiff.device)\n",
    "        pdiff = torch.cat([null_column, pdiff], dim=1)\n",
    "        pdiff[:,-1]=0\n",
    "        nstep = get_first_zero_index(pdiff)\n",
    "        pred_model= torch.gather(pstep, 1, nstep).flatten()\n",
    "        acc_model = torch.eq(pred_model.cpu(), y_hot.max(dim=1)[1])\n",
    "        return (nstep.flatten()+1).cpu().numpy(), pred_model, acc_model\n",
    "\n",
    "    nstep, pred_model, acc_model_check = get_nstep(objcaps_len_step_narrow, y_hot)\n",
    "    assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "\n",
    "    # get trial id that requires 2 steps and 3 steps among correct trials\n",
    "    nstep_masked = acc_model.cpu().numpy()*nstep\n",
    "    id_incorrect = list(np.where(nstep_masked==0)[0])\n",
    "    id_correct = list(np.where(nstep_masked!=0)[0])    \n",
    "    print('correct: ', len(id_correct) )\n",
    "    print('incorrect: ', len(id_incorrect) )\n",
    "\n",
    "    id_step2 = list(np.where(nstep_masked==2)[0])\n",
    "    id_step3 = list(np.where(nstep_masked==3)[0])\n",
    "    id_step4 = list(np.where(nstep_masked==4)[0])\n",
    "    id_step34 = id_step3 + id_step4\n",
    "    \n",
    "    print('step2: ', len(id_step2))\n",
    "    print('step3: ', len(id_step3))\n",
    "    print('step4: ', len(id_step4))\n",
    "\n",
    "    # save tiralist to dictionary\n",
    "    d_triallist[corruption]['step2'] = id_step2\n",
    "    d_triallist[corruption]['step3'] = id_step3\n",
    "    d_triallist[corruption]['step4'] = id_step4\n",
    "    d_triallist[corruption]['correct'] = id_correct\n",
    "    d_triallist[corruption]['incorrect'] = id_incorrect\n",
    "\n",
    "    # get 20 randomly sampled image from each and save\n",
    "    MAX_TRIAL = 20\n",
    "    id_step2_sampled = random.sample(id_step2, min(len(id_step2),MAX_TRIAL))\n",
    "    id_step34_sampled = random.sample(id_step34, min(len(id_step34), MAX_TRIAL))\n",
    "                                \n",
    "    for step in ['step2', 'step3', 'step4']: ## ['step2', 'step3', 'step4']\n",
    "        if step=='step2':\n",
    "            trialid_to_visualize = id_step2_sampled \n",
    "        elif step=='step3':\n",
    "            trialid_to_visualize = [ti for ti in id_step3 if ti in id_step34_sampled]\n",
    "        elif step=='step4':\n",
    "            trialid_to_visualize = [ti for ti in id_step4 if ti in id_step34_sampled]\n",
    "        \n",
    "        for trialid in trialid_to_visualize:\n",
    "            our_pred = pred_model[trialid].cpu().item()\n",
    "            gt =y_hot.max(dim=1)[1][trialid].cpu().item()\n",
    "\n",
    "            # save image x8 original pixel size\n",
    "            imgarray = x[trialid].numpy()\n",
    "            filename = f'{corruption}_{step}_t{trialid}_g{gt}_o{our_pred}.png'\n",
    "            save_imgarr(np.transpose(imgarray,(1,2,0)), filename= path_save+filename)\n",
    "            \n",
    "    print('all images are saved')\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# ==> corruption type: shot_noise, this batch acc: 0.9418999552726746\n",
    "# incorrect:  581\n",
    "# step2:  9380\n",
    "# step3:  22\n",
    "# step4:  17\n",
    "\n",
    "\n",
    "# ==> corruption type: impulse_noise, this batch acc: 0.9120000004768372\n",
    "# incorrect:  880\n",
    "# step2:  7934\n",
    "# step3:  1089\n",
    "# step4:  97\n",
    "\n",
    "# ==> corruption type: glass_blur, this batch acc: 0.8628000020980835\n",
    "# incorrect:  1372\n",
    "# step2:  8387\n",
    "# step3:  201\n",
    "# step4:  40\n",
    "\n",
    "# ==> corruption type: motion_blur, this batch acc: 0.936199963092804\n",
    "# incorrect:  638\n",
    "# step2:  9297\n",
    "# step3:  51\n",
    "# step4:  14\n",
    "\n",
    "# ==> corruption type: shear, this batch acc: 0.9767999649047852\n",
    "# incorrect:  232\n",
    "# step2:  9742\n",
    "# step3:  26\n",
    "# step4:  0\n",
    "\n",
    "# ==> corruption type: scale, this batch acc: 0.9440999627113342\n",
    "# incorrect:  559\n",
    "# step2:  9432\n",
    "# step3:  3\n",
    "# step4:  6\n",
    "\n",
    "# ==> corruption type: rotate, this batch acc: 0.9200999736785889\n",
    "# incorrect:  799\n",
    "# step2:  9162\n",
    "# step3:  34\n",
    "# step4:  5\n",
    "\n",
    "# ==> corruption type: brightness, this batch acc: 0.9892999529838562\n",
    "# incorrect:  107\n",
    "# step2:  9890\n",
    "# step3:  3\n",
    "# step4:  0\n",
    "\n",
    "# ==> corruption type: translate, this batch acc: 0.47119998931884766\n",
    "# incorrect:  5288\n",
    "# step2:  4577\n",
    "# step3:  101\n",
    "# step4:  34\n",
    "\n",
    "# ==> corruption type: stripe, this batch acc: 0.836899995803833\n",
    "# incorrect:  1631\n",
    "# step2:  8205\n",
    "# step3:  154\n",
    "# step4:  10\n",
    "\n",
    "# ==> corruption type: fog, this batch acc: 0.8615999817848206\n",
    "# incorrect:  1384\n",
    "# step2:  5842\n",
    "# step3:  2715\n",
    "# step4:  59\n",
    "\n",
    "# ==> corruption type: spatter, this batch acc: 0.9839999675750732\n",
    "# incorrect:  160\n",
    "# step2:  9794\n",
    "# step3:  41\n",
    "# step4:  5\n",
    "\n",
    "    \n",
    "# ==> corruption type: dotted_line, this batch acc: 0.983299970626831\n",
    "# incorrect:  167\n",
    "# step2:  9777\n",
    "# step3:  53\n",
    "# step4:  3\n",
    "\n",
    "# ==> corruption type: zigzag, this batch acc: 0.952299952507019\n",
    "# incorrect:  477\n",
    "# step2:  9395\n",
    "# step3:  118\n",
    "# step4:  10\n",
    "\n",
    "# ==> corruption type: canny_edges, this batch acc: 0.6972999572753906\n",
    "# incorrect:  3027\n",
    "# step2:  6704\n",
    "# step3:  224\n",
    "# step4:  45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e5a093-2513-4e09-83a0-ed7fca666fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change filenames\n",
    "# import os\n",
    "# path = './stimuli/stimuli-exp1-step4/'\n",
    "\n",
    "# for f in os.listdir(path):\n",
    "#     if not f.startswith('.'):\n",
    "#         fsplit = f.split('_')\n",
    "#         stepsize = fsplit[-1].split('.')[0]\n",
    "#         corruption =  fsplit[:-4]\n",
    "#         newf = '_'.join(corruption + [stepsize] + fsplit[-4:-1] ) + '.png'\n",
    "#         os.rename(path+f, path+newf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad7bb6",
   "metadata": {},
   "source": [
    "# experiment 2: compare with cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924cf182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 4\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "original is used\n",
      "==> corruption type: glass_blur, this batch acc: 0.8671000003814697\n",
      "original is used\n",
      "==> corruption type: glass_blur, this batch acc: 0.9012999534606934\n",
      "178\n",
      "trialinfo saved to disk!\n",
      "original is used\n",
      "==> corruption type: brightness, this batch acc: 0.9884999990463257\n",
      "original is used\n",
      "==> corruption type: brightness, this batch acc: 0.876800000667572\n",
      "30\n",
      "trialinfo saved to disk!\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# test a single model, and visualize outputs\n",
    "#############################\n",
    "task='mnist_c_original'\n",
    "# task='mnist_c_original'\n",
    "# task='mnist_recon'\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "\n",
    "# load our model\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 4, 'routings': 3, 'routing_type': 'pd-recon', #'original' \n",
    "                 'min_coup': 0.5, 'min_rscore': 0.5, 'mask_threshold': 0.1}\n",
    "# load_model_path ='./results/mnist/Mar21_0248_run3/archive_model_epoch50_acc0.9907.pt'\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt'\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "# load cnn\n",
    "from train_cnn import *\n",
    "path_cnn = './models/cnn/cnn_best.pt'\n",
    "cnn = Net().to(DEVICE)\n",
    "cnn.load_state_dict(torch.load(path_cnn))\n",
    "cnn.eval()\n",
    "\n",
    "path_save = './stimuli/stimuli-exp2-step4/'\n",
    "\n",
    "\n",
    "\n",
    "# obtain model predictions\n",
    "\n",
    "for corruption_index in [4, 9]:\n",
    "\n",
    "    corruption =CORRUPTION_TYPES[corruption_index-1]\n",
    "    \n",
    "\n",
    "    if task == 'mnist_c_mini':\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step, outputs_model  = \\\n",
    "        evaluate_model_on_mnistc_mini(corruption, model, args, train, verbose=False, save_hooks=True, max_batch_num=None)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    elif task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "        evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    else:\n",
    "        batchnum=3*int(1000/BATCHSIZE)-1\n",
    "        x, gtx, y, objcaps_len_step, x_recon_step, outputs = evaluate_on_batch(task, batchnum, model, args, train)\n",
    "\n",
    "    # get model prediction\n",
    "    objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "    # pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "\n",
    "    def get_nstep(objcaps_len_step_narrow, y_hot):\n",
    "        def get_first_zero_index(x, axis=1):\n",
    "            cond = (x == 0)\n",
    "            return ((cond.cumsum(axis) == 1) & cond).max(axis, keepdim=True)[1]\n",
    "\n",
    "        pstep = objcaps_len_step_narrow.max(dim=-1)[1]\n",
    "        pnow = pstep[:,1:]\n",
    "        pbefore = pstep[:,:-1]\n",
    "\n",
    "        pdiff = (pnow-pbefore)\n",
    "        null_column = -99*torch.ones(pdiff.size(0),1).to(pdiff.device)\n",
    "        pdiff = torch.cat([null_column, pdiff], dim=1)\n",
    "        pdiff[:,-1]=0\n",
    "        nstep = get_first_zero_index(pdiff)\n",
    "        pred_model= torch.gather(pstep, 1, nstep).flatten()\n",
    "        acc_model = torch.eq(pred_model.cpu(), y_hot.max(dim=1)[1])\n",
    "        return (nstep.flatten()+1).cpu().numpy(), pred_model, acc_model\n",
    "\n",
    "    nstep, pred_model, acc_model_check = get_nstep(objcaps_len_step_narrow, y_hot)\n",
    "    assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "\n",
    "    ##################\n",
    "    # get cnn prediction\n",
    "    ##################\n",
    "    if task == 'mnist_c_mini':\n",
    "        data_cnn, target_cnn, logsoft_cnn, pred_cnn, acc_cnn \\\n",
    "        = evaluate_cnn_on_mnistc_mini(corruption, cnn, max_batch_num=None)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_cnn.float().mean().item()}')\n",
    "    elif task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        data_cnn, target_cnn, logsoft_cnn, pred_cnn, acc_cnn \\\n",
    "        =  evaluate_cnn_on_mnistc_original(corruption, cnn)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_cnn.float().mean().item()}')\n",
    "        \n",
    "        \n",
    "    #######################\n",
    "    # get trials id where both model fails & disagree\n",
    "    #######################\n",
    "    assert (target_cnn.cpu() == y_hot.max(dim=1)[1].cpu()).all()\n",
    "    bool_bothincorrect = ~(acc_model.bool())* ~(acc_cnn.bool())\n",
    "    bool_diffanswer = (pred_model!= pred_cnn)\n",
    "    bool_onlycnncorrect = ~(acc_model.bool())* (acc_cnn.bool())\n",
    "    # idx_bothincorrect = torch.nonzero(bool_bothincorrect)\n",
    "    trialid_interest = torch.nonzero(bool_bothincorrect*bool_diffanswer).flatten().tolist()\n",
    "    # trialid_interest = torch.nonzero(bool_onlycnncorrect*bool_diffanswer).flatten().tolist()\n",
    "    print(len(trialid_interest))\n",
    "    \n",
    "    #####################\n",
    "    # save image (in reverted grayscale) and trialinfo\n",
    "    #####################\n",
    "\n",
    "    d = collections.defaultdict(dict)\n",
    "    MAX_TRIAL = 20\n",
    "\n",
    "    trialid_to_visualize = random.sample(trialid_interest, min(len(trialid_interest), MAX_TRIAL))\n",
    "\n",
    "    for trialid in trialid_to_visualize:\n",
    "        cnn_pred = pred_cnn[trialid].cpu().item()\n",
    "        our_pred = pred_model[trialid].cpu().item()\n",
    "        gt =target_cnn[trialid].cpu().item()\n",
    "\n",
    "        # save image x8 original pixel size\n",
    "        imgarray = x[trialid].numpy()\n",
    "        filename = f'{corruption}_t{trialid}_g{gt}_c{cnn_pred}_o{our_pred}.png'\n",
    "        save_imgarr(np.transpose(imgarray,(1,2,0)), filename=path_save+filename)\n",
    "\n",
    "        # save trial info to dictionary\n",
    "        d[filename]['id'] = trialid\n",
    "        d[filename]['imgarray'] = imgarray.tolist()\n",
    "        d[filename]['cnn_softmax'] = torch.exp(logsoft_cnn[trialid]).cpu().numpy().tolist()\n",
    "        d[filename]['our_objlen'] = objcaps_len_step_narrow[trialid, -1].cpu().numpy().tolist()\n",
    "        d[filename]['cnn_pred'] = cnn_pred\n",
    "        d[filename]['our_pred'] = our_pred\n",
    "        d[filename]['gt'] =  gt\n",
    "\n",
    "\n",
    "    # save dictionary\n",
    "    with open(path_save+ f'{corruption}.json', 'w') as fp:\n",
    "        json.dump(d, fp)\n",
    "    print('trialinfo saved to disk!')    \n",
    "    # to open\n",
    "    # with open('./stimuli/glass_blur.json') as json_file:\n",
    "    #     test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867598c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
