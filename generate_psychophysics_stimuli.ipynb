{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce89847a-5da6-4757-ae72-9905206945cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization import *\n",
    "from rrcapsnet_original import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "N_MINI_PER_CORRUPTION = 1000\n",
    "\n",
    "ACC_TYPE = \"entropy\"\n",
    "\n",
    "# general helper funtions for model testing\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "\n",
    "###########################\n",
    "# evaluate on mnist-c original version\n",
    "############################\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False,  max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "    \n",
    "    model.eval()      \n",
    "    \n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "                \n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "\n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "\n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()        \n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_original(corruption, cnn, max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "    cnn.eval() \n",
    "\n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "\n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "                    \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "\n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50e977f-63b6-4307-a19c-01982d74457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "\n",
    "def save_imgarr(imgarr, filename='test.png', scale=8):\n",
    "    h, w, _ = imgarr.shape\n",
    "    fig, axes = plt.subplots(figsize=(h*scale, w*scale))\n",
    "    fig.subplots_adjust(top=1.0, bottom=0, right=1.0, left=0, hspace=0, wspace=0) \n",
    "    axes.imshow(imgarr, cmap='gray_r')\n",
    "    axes.axis('off')\n",
    "    plt.savefig(filename, dpi=1, format='png') \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50981e4b",
   "metadata": {},
   "source": [
    "# experiment 1: timestep vs RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#############################\n",
    "# test a single model, and visualize outputs\n",
    "#############################\n",
    "task='mnist_c_original'\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "\n",
    "# load model\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings': 3,'mask_threshold': 0.1}\n",
    "\n",
    "# load_model_path = './models/rrcapsnet/rrcapsnet_best.pt'\n",
    "load_model_path = './results/mnist/Aug14_0508_lsf_res4_run1/best_epoch30_acc1.0000.pt'\n",
    "\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "path_save = './stimuli/stimuli-exp1-step5/'\n",
    "#  obtain model prediction\n",
    "\n",
    "d_triallist = {}\n",
    "\n",
    "for corruption_index in [13]:\n",
    "\n",
    "    corruption =CORRUPTION_TYPES[corruption_index-1]\n",
    "    \n",
    "    d_triallist[corruption] = {}\n",
    "    \n",
    "    if task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "        evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # get model prediction\n",
    "    objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "    # pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "    if ACC_TYPE=='hypothesis':\n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else:\n",
    "            acc_model_check, pred_model, nstep  = compute_hypothesis_based_acc(objcaps_len_step_narrow, y_hot, only_acc=False)\n",
    "\n",
    "    elif ACC_TYPE == 'entropy':    \n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else: \n",
    "            acc_model_check, pred_model, nstep, no_stop_condition, entropy_model =compute_entropy_based_acc(objcaps_len_step_narrow, y_hot, threshold=0.6, use_cumulative = False, only_acc= False)\n",
    "\n",
    "    assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "    # get trial id that requires 2 steps and 3 steps among correct trials\n",
    "    nstep_masked = acc_model.cpu().numpy()*nstep.cpu().numpy()\n",
    "    id_incorrect = list(np.where(nstep_masked==0)[0])\n",
    "    id_correct = list(np.where(nstep_masked!=0)[0])    \n",
    "    print('correct: ', len(id_correct) )\n",
    "    print('incorrect: ', len(id_incorrect) )\n",
    "\n",
    "    id_step1 = list(np.where(nstep_masked==1)[0])    \n",
    "    id_step2 = list(np.where(nstep_masked==2)[0])\n",
    "    id_step3 = list(np.where(nstep_masked==3)[0])\n",
    "    id_step4 = list(np.where(nstep_masked==4)[0])\n",
    "    id_step5 = list(np.where(nstep_masked==5)[0])\n",
    "    \n",
    "    print('step1: ', len(id_step1))    \n",
    "    print('step2: ', len(id_step2))\n",
    "    print('step3: ', len(id_step3))\n",
    "    print('step4: ', len(id_step4))\n",
    "    print('step5: ', len(id_step5))\n",
    "\n",
    "    # save tiralist to dictionary\n",
    "    d_triallist[corruption]['step1'] = id_step1\n",
    "    d_triallist[corruption]['step2'] = id_step2\n",
    "    d_triallist[corruption]['step3'] = id_step3\n",
    "    d_triallist[corruption]['step4'] = id_step4\n",
    "    d_triallist[corruption]['step5'] = id_step4    \n",
    "    d_triallist[corruption]['correct'] = id_correct\n",
    "    d_triallist[corruption]['incorrect'] = id_incorrect\n",
    "\n",
    "    # get 20 randomly sampled image from each and save\n",
    "    MAX_TRIAL = 20\n",
    "    id_step1_sampled = random.sample(id_step1, min(len(id_step1),MAX_TRIAL))\n",
    "    id_step2_sampled = random.sample(id_step2, min(len(id_step1),MAX_TRIAL))\n",
    "\n",
    "                                \n",
    "    for step in ['step1', 'step2']: \n",
    "        if step=='step1':\n",
    "            trialid_to_visualize = id_step1_sampled \n",
    "        elif step=='step2':\n",
    "            trialid_to_visualize = id_step2_sampled \n",
    "#         elif step=='step3':\n",
    "#             trialid_to_visualize = [ti for ti in id_step3 if ti in id_step34_sampled]\n",
    "        \n",
    "        for trialid in trialid_to_visualize:\n",
    "            our_pred = pred_model[trialid].cpu().item()\n",
    "            gt =y_hot.max(dim=1)[1][trialid].cpu().item()\n",
    "\n",
    "            # save image x8 original pixel size\n",
    "            imgarray = x[trialid].numpy()\n",
    "            filename = f'{corruption}_{step}_t{trialid}_g{gt}_o{our_pred}.png'\n",
    "            save_imgarr(np.transpose(imgarray,(1,2,0)), filename= path_save+filename)\n",
    "            \n",
    "    print('all images are saved')\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e5a093-2513-4e09-83a0-ed7fca666fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change filenames\n",
    "# import os\n",
    "# path = './stimuli/stimuli-exp1-step4/'\n",
    "\n",
    "# for f in os.listdir(path):\n",
    "#     if not f.startswith('.'):\n",
    "#         fsplit = f.split('_')\n",
    "#         stepsize = fsplit[-1].split('.')[0]\n",
    "#         corruption =  fsplit[:-4]\n",
    "#         newf = '_'.join(corruption + [stepsize] + fsplit[-4:-1] ) + '.png'\n",
    "#         os.rename(path+f, path+newf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad7bb6",
   "metadata": {},
   "source": [
    "# experiment 2: compare with cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924cf182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 5\n",
      "ENCODER: resnet w/ None projection\n",
      "...resulting primary caps #: 288, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "original is used\n",
      "==> corruption type: fog, this batch acc: 0.9733999967575073\n",
      "original is used\n",
      "==> corruption type: fog, this batch acc: 0.840999960899353\n",
      "58\n",
      "trialinfo saved to disk!\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# test a single model, and visualize outputs\n",
    "#############################\n",
    "task='mnist_c_original'\n",
    "\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "\n",
    "# load our model\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings': 3,'mask_threshold': 0.1}\n",
    "\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt'\n",
    "load_model_path = './results/mnist/Aug14_0508_lsf_res4_run1/best_epoch30_acc1.0000.pt'\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "# load cnn\n",
    "from train_cnn import *\n",
    "path_cnn = './models/cnn/cnn_best.pt'\n",
    "cnn = Net().to(DEVICE)\n",
    "cnn.load_state_dict(torch.load(path_cnn))\n",
    "cnn.eval()\n",
    "\n",
    "path_save = './stimuli/stimuli-exp2-step5/'\n",
    "\n",
    "\n",
    "\n",
    "# obtain model predictions\n",
    "\n",
    "for corruption_index in [12]:\n",
    "\n",
    "    corruption =CORRUPTION_TYPES[corruption_index-1]\n",
    "    \n",
    "\n",
    "    if task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "        evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # get model prediction\n",
    "    objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "    # pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "\n",
    "    if ACC_TYPE=='hypothesis':\n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else:\n",
    "            acc_model_check, pred_model, nstep  = compute_hypothesis_based_acc(objcaps_len_step_narrow, y_hot, only_acc=False)\n",
    "\n",
    "    elif ACC_TYPE == 'entropy':    \n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else: \n",
    "            acc_model_check, pred_model, nstep, no_stop_condition, entropy_model =compute_entropy_based_acc(objcaps_len_step_narrow, y_hot, threshold=0.6, use_cumulative = False, only_acc= False)\n",
    "\n",
    "    assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "\n",
    "    ##################\n",
    "    # get cnn prediction\n",
    "    ##################\n",
    "    if task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        data_cnn, target_cnn, logsoft_cnn, pred_cnn, acc_cnn \\\n",
    "        =  evaluate_cnn_on_mnistc_original(corruption, cnn)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_cnn.float().mean().item()}')\n",
    "        \n",
    "        \n",
    "    #######################\n",
    "    # get trials id where both model fails & disagree\n",
    "    #######################\n",
    "    assert (target_cnn.cpu() == y_hot.max(dim=1)[1].cpu()).all()\n",
    "    bool_bothincorrect = ~(acc_model.bool())* ~(acc_cnn.bool())\n",
    "    bool_diffanswer = (pred_model!= pred_cnn)\n",
    "    bool_onlycnncorrect = ~(acc_model.bool())* (acc_cnn.bool())\n",
    "    # idx_bothincorrect = torch.nonzero(bool_bothincorrect)\n",
    "    trialid_interest = torch.nonzero(bool_bothincorrect*bool_diffanswer).flatten().tolist()\n",
    "    # trialid_interest = torch.nonzero(bool_onlycnncorrect*bool_diffanswer).flatten().tolist()\n",
    "    print(len(trialid_interest))\n",
    "    \n",
    "    #####################\n",
    "    # save image (in reverted grayscale) and trialinfo\n",
    "    #####################\n",
    "\n",
    "    d = collections.defaultdict(dict)\n",
    "    MAX_TRIAL = 20\n",
    "\n",
    "    trialid_to_visualize = random.sample(trialid_interest, min(len(trialid_interest), MAX_TRIAL))\n",
    "\n",
    "    for trialid in trialid_to_visualize:\n",
    "        cnn_pred = pred_cnn[trialid].cpu().item()\n",
    "        our_pred = pred_model[trialid].cpu().item()\n",
    "        gt =target_cnn[trialid].cpu().item()\n",
    "\n",
    "        # save image x8 original pixel size\n",
    "        imgarray = x[trialid].numpy()\n",
    "        filename = f'{corruption}_t{trialid}_g{gt}_c{cnn_pred}_o{our_pred}.png'\n",
    "        save_imgarr(np.transpose(imgarray,(1,2,0)), filename=path_save+filename)\n",
    "\n",
    "        # save trial info to dictionary\n",
    "        d[filename]['id'] = trialid\n",
    "        d[filename]['imgarray'] = imgarray.tolist()\n",
    "        d[filename]['cnn_softmax'] = torch.exp(logsoft_cnn[trialid]).cpu().numpy().tolist()\n",
    "        d[filename]['our_objlen'] = objcaps_len_step_narrow[trialid, -1].cpu().numpy().tolist()\n",
    "        d[filename]['cnn_pred'] = cnn_pred\n",
    "        d[filename]['our_pred'] = our_pred\n",
    "        d[filename]['gt'] =  gt\n",
    "\n",
    "\n",
    "    # save dictionary\n",
    "    with open(path_save+ f'{corruption}.json', 'w') as fp:\n",
    "        json.dump(d, fp)\n",
    "    print('trialinfo saved to disk!')    \n",
    "    # to open\n",
    "    # with open('./stimuli/glass_blur.json') as json_file:\n",
    "    #     test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867598c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
