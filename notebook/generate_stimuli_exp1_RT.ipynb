{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set current directory (where this repo is located)\n",
    "import os\n",
    "PROJECT_ROOT = '/home/young/workspace/reconstruction/recon-mnistc'\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print('current directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce89847a-5da6-4757-ae72-9905206945cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization import *\n",
    "from ourmodel import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "N_MINI_PER_CORRUPTION = 1000\n",
    "\n",
    "ACC_TYPE = \"entropy\"\n",
    "\n",
    "# general helper funtions for model testing\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "\n",
    "###########################\n",
    "# evaluate on mnist-c original version\n",
    "############################\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False,  max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "    \n",
    "    model.eval()      \n",
    "    \n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "                \n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "\n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "\n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()        \n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_original(corruption, cnn, max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "    cnn.eval() \n",
    "\n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "\n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "                    \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "\n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50e977f-63b6-4307-a19c-01982d74457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "\n",
    "def save_imgarr(imgarr, filename='test.png', scale=8):\n",
    "    h, w, _ = imgarr.shape\n",
    "    fig, axes = plt.subplots(figsize=(h*scale, w*scale))\n",
    "    fig.subplots_adjust(top=1.0, bottom=0, right=1.0, left=0, hspace=0, wspace=0) \n",
    "    axes.imshow(imgarr, cmap='gray_r')\n",
    "    axes.axis('off')\n",
    "    plt.savefig(filename, dpi=1, format='png') \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50981e4b",
   "metadata": {},
   "source": [
    "# experiment 1: timestep vs RT on accurate trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b3fb5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 5\n",
      "ENCODER: resnet w/ None projection\n",
      "...resulting primary caps #: 288, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "original is used\n",
      "==> corruption type: identity, this batch acc: 0.9937999844551086\n",
      "\n",
      "========   identity   ========\n",
      "correct:  9938\n",
      "incorrect:  62\n",
      "step1:  9847\n",
      "step2:  26\n",
      "step3:  7\n",
      "step4:  1\n",
      "step5:  57\n",
      "original is used\n",
      "==> corruption type: glass_blur, this batch acc: 0.9411999583244324\n",
      "\n",
      "========   glass_blur   ========\n",
      "correct:  9412\n",
      "incorrect:  588\n",
      "step1:  8551\n",
      "step2:  442\n",
      "step3:  77\n",
      "step4:  22\n",
      "step5:  320\n",
      "original is used\n",
      "==> corruption type: motion_blur, this batch acc: 0.9667999744415283\n",
      "\n",
      "========   motion_blur   ========\n",
      "correct:  9668\n",
      "incorrect:  332\n",
      "step1:  9052\n",
      "step2:  360\n",
      "step3:  36\n",
      "step4:  15\n",
      "step5:  205\n",
      "original is used\n",
      "==> corruption type: impulse_noise, this batch acc: 0.9702999591827393\n",
      "\n",
      "========   impulse_noise   ========\n",
      "correct:  9703\n",
      "incorrect:  297\n",
      "step1:  7750\n",
      "step2:  1552\n",
      "step3:  188\n",
      "step4:  55\n",
      "step5:  158\n",
      "original is used\n",
      "==> corruption type: shot_noise, this batch acc: 0.9765999913215637\n",
      "\n",
      "========   shot_noise   ========\n",
      "correct:  9766\n",
      "incorrect:  234\n",
      "step1:  9609\n",
      "step2:  43\n",
      "step3:  15\n",
      "step4:  2\n",
      "step5:  97\n",
      "original is used\n",
      "==> corruption type: fog, this batch acc: 0.9733999967575073\n",
      "\n",
      "========   fog   ========\n",
      "correct:  9734\n",
      "incorrect:  266\n",
      "step1:  912\n",
      "step2:  8265\n",
      "step3:  401\n",
      "step4:  75\n",
      "step5:  81\n",
      "original is used\n",
      "==> corruption type: dotted_line, this batch acc: 0.9846999645233154\n",
      "\n",
      "========   dotted_line   ========\n",
      "correct:  9847\n",
      "incorrect:  153\n",
      "step1:  9164\n",
      "step2:  565\n",
      "step3:  48\n",
      "step4:  7\n",
      "step5:  63\n",
      "original is used\n",
      "==> corruption type: spatter, this batch acc: 0.9824000000953674\n",
      "\n",
      "========   spatter   ========\n",
      "correct:  9824\n",
      "incorrect:  176\n",
      "step1:  9535\n",
      "step2:  117\n",
      "step3:  20\n",
      "step4:  4\n",
      "step5:  148\n",
      "original is used\n",
      "==> corruption type: zigzag, this batch acc: 0.9291999936103821\n",
      "\n",
      "========   zigzag   ========\n",
      "correct:  9292\n",
      "incorrect:  708\n",
      "step1:  7662\n",
      "step2:  1184\n",
      "step3:  217\n",
      "step4:  72\n",
      "step5:  157\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# get nsteps for correct trials \n",
    "########\n",
    "\n",
    "task='mnist_c_original'\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "\n",
    "# load model\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings': 3,'mask_threshold': 0.1}\n",
    "\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt' #run1\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "#  obtain model prediction\n",
    "\n",
    "d_triallist = {}\n",
    "CORRUPTION_INTEREST = ['identity', 'glass_blur','motion_blur', 'impulse_noise','shot_noise',\n",
    "        'fog','dotted_line','spatter', 'zigzag']\n",
    "\n",
    "for corruption in CORRUPTION_INTEREST :\n",
    "\n",
    "    d_triallist[corruption] = {}\n",
    "    \n",
    "    if task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "        evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # get model prediction\n",
    "    objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "    # pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "    if ACC_TYPE=='hypothesis':\n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else:\n",
    "            acc_model_check, pred_model, nstep  = compute_hypothesis_based_acc(objcaps_len_step_narrow, y_hot, only_acc=False)\n",
    "\n",
    "    elif ACC_TYPE == 'entropy':    \n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else: \n",
    "            acc_model_check, pred_model, nstep, no_stop_condition, entropy_model =compute_entropy_based_acc(objcaps_len_step_narrow, y_hot, threshold=0.6, use_cumulative = False, only_acc= False)\n",
    "\n",
    "    assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "    # get accurate trials\n",
    "    nstep_masked = acc_model.cpu().numpy()*nstep.cpu().numpy()\n",
    "    id_incorrect = np.where(nstep_masked==0)[0].tolist()\n",
    "    id_correct = np.where(nstep_masked!=0)[0].tolist()\n",
    "    print('\\n========  ', corruption, '  ========')\n",
    "    print('correct: ', len(id_correct) )\n",
    "    print('incorrect: ', len(id_incorrect) )\n",
    "#     d_triallist[corruption]['correct'] = id_correct\n",
    "#     d_triallist[corruption]['incorrect'] = id_incorrect\n",
    "    \n",
    "    # trial ids that take N steps to finish recognition\n",
    "    POSSIBLE_NSTEP = [1, 2, 3, 4, 5]\n",
    "    for n in POSSIBLE_NSTEP:\n",
    "        id_step = np.where(nstep_masked==n)[0].tolist()\n",
    "        d_triallist[corruption][f'step{n}'] = id_step\n",
    "        print(f'step{n}: ', len(id_step))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c939f9d-a0d7-4fd3-9c89-22b32d5bab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>glass_blur</th>\n",
       "      <th>motion_blur</th>\n",
       "      <th>impulse_noise</th>\n",
       "      <th>shot_noise</th>\n",
       "      <th>fog</th>\n",
       "      <th>dotted_line</th>\n",
       "      <th>spatter</th>\n",
       "      <th>zigzag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step1</th>\n",
       "      <td>9847</td>\n",
       "      <td>8551</td>\n",
       "      <td>9052</td>\n",
       "      <td>7750</td>\n",
       "      <td>9609</td>\n",
       "      <td>912</td>\n",
       "      <td>9164</td>\n",
       "      <td>9535</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step2</th>\n",
       "      <td>26</td>\n",
       "      <td>442</td>\n",
       "      <td>360</td>\n",
       "      <td>1552</td>\n",
       "      <td>43</td>\n",
       "      <td>8265</td>\n",
       "      <td>565</td>\n",
       "      <td>117</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step3</th>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>36</td>\n",
       "      <td>188</td>\n",
       "      <td>15</td>\n",
       "      <td>401</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step4</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step5</th>\n",
       "      <td>57</td>\n",
       "      <td>320</td>\n",
       "      <td>205</td>\n",
       "      <td>158</td>\n",
       "      <td>97</td>\n",
       "      <td>81</td>\n",
       "      <td>63</td>\n",
       "      <td>148</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      identity glass_blur motion_blur impulse_noise shot_noise   fog  \\\n",
       "step1     9847       8551        9052          7750       9609   912   \n",
       "step2       26        442         360          1552         43  8265   \n",
       "step3        7         77          36           188         15   401   \n",
       "step4        1         22          15            55          2    75   \n",
       "step5       57        320         205           158         97    81   \n",
       "\n",
       "      dotted_line spatter zigzag  \n",
       "step1        9164    9535   7662  \n",
       "step2         565     117   1184  \n",
       "step3          48      20    217  \n",
       "step4           7       4     72  \n",
       "step5          63     148    157  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save dictionary and summary stats\n",
    "import json\n",
    "with open('./results/nstep_trialid.json', 'w') as fp:\n",
    "    json.dump(d_triallist, fp)\n",
    "    \n",
    "# get counts for each condition (nstep)\n",
    "cols = list(d_triallist)\n",
    "rows = list(d_triallist[cols[0]])\n",
    "countdf = pd.DataFrame(columns=cols, index=rows)\n",
    "\n",
    "for c in cols:\n",
    "    for r in rows:\n",
    "        countdf.loc[r,c] = len(d_triallist[c][r])\n",
    "        \n",
    "countdf.to_csv('./results/corruption_nstep_count.csv')\n",
    "countdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c26bb-9c76-47b1-b71f-cedd3b36e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# sample stimuli from each condition\n",
    "##########\n",
    "# low: 20 trials from step 1\n",
    "# med: 20 trials from step2 and 3\n",
    "# high: 20 trials from step4 and 5\n",
    "import gc\n",
    "import json\n",
    "\n",
    "with open('./results/nstep_trialid.json', 'r') as fp:\n",
    "    d_triallist = json.load(fp)\n",
    "    \n",
    "corruption = 'identity'\n",
    "# ['identity', 'glass_blur','motion_blur', 'impulse_noise','shot_noise',\n",
    "#         'fog','dotted_line','spatter', 'zigzag']\n",
    "\n",
    "\n",
    "N_TRIAL_PER_CONDITON=20\n",
    "\n",
    "id_step1_sampled = random.sample(d_triallist[corruption]['step1'], N_TRIAL_PER_CONDITON)\n",
    "id_step23_sampled = random.sample(d_triallist[corruption]['step2']+d_triallist[corruption]['step3'], N_TRIAL_PER_CONDITON)\n",
    "id_step45_sampled = random.sample(d_triallist[corruption]['step4']+d_triallist[corruption]['step5'], N_TRIAL_PER_CONDITON)\n",
    "\n",
    "#########\n",
    "# load model predictions for stimuli info\n",
    "#########\n",
    "task='mnist_c_original'\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings': 3,'mask_threshold': 0.1}\n",
    "\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt' #run1\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "if task =='mnist_c_original':\n",
    "    print(\"original is used\")\n",
    "    x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "    evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "    print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# get model prediction\n",
    "objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "# pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "if ACC_TYPE=='hypothesis':\n",
    "    if args.time_steps==1:\n",
    "        y_pred = objcaps_len_step_narrow[:,-1]\n",
    "        accs = topkacc(y_pred, y_true, topk=1)\n",
    "    else:\n",
    "        acc_model_check, pred_model, nstep  = compute_hypothesis_based_acc(objcaps_len_step_narrow, y_hot, only_acc=False)\n",
    "\n",
    "elif ACC_TYPE == 'entropy':    \n",
    "    if args.time_steps==1:\n",
    "        y_pred = objcaps_len_step_narrow[:,-1]\n",
    "        accs = topkacc(y_pred, y_true, topk=1)\n",
    "    else: \n",
    "        acc_model_check, pred_model, nstep, no_stop_condition, entropy_model =compute_entropy_based_acc(objcaps_len_step_narrow, y_hot, threshold=0.6, use_cumulative = False, only_acc= False)\n",
    "\n",
    "assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "########\n",
    "# generate and save stimuli\n",
    "########\n",
    "path_save = './stimuli/stimuli-exp1-step5/'\n",
    "POSSIBLE_NSTEP = list(d_triallist[corruption])\n",
    "\n",
    "for step in POSSIBLE_NSTEP:              \n",
    "    if step=='step1':\n",
    "        trialid_to_visualize = id_step1_sampled \n",
    "    elif step=='step2' or step=='step3':\n",
    "        trialid_to_visualize = [ti for ti in d_triallist[corruption][step] if ti in id_step23_sampled]\n",
    "    elif step=='step4' or step=='step5':\n",
    "        trialid_to_visualize = [ti for ti in d_triallist[corruption][step] if ti in id_step45_sampled]    \n",
    "\n",
    "    for trialid in trialid_to_visualize:\n",
    "        our_pred = pred_model[trialid].cpu().item()\n",
    "        gt =y_hot.max(dim=1)[1][trialid].cpu().item()\n",
    "\n",
    "        # save image x8 original pixel size\n",
    "        imgarray = x[trialid].numpy()\n",
    "        filename = f'{corruption}_{step}_t{trialid}_g{gt}_o{our_pred}.png'\n",
    "        save_imgarr(np.transpose(imgarray,(1,2,0)), filename= path_save+filename)\n",
    "\n",
    "print('all images are saved')\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e5a093-2513-4e09-83a0-ed7fca666fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change filenames\n",
    "# import os\n",
    "# path = './stimuli/stimuli-exp1-step4/'\n",
    "\n",
    "# for f in os.listdir(path):\n",
    "#     if not f.startswith('.'):\n",
    "#         fsplit = f.split('_')\n",
    "#         stepsize = fsplit[-1].split('.')[0]\n",
    "#         corruption =  fsplit[:-4]\n",
    "#         newf = '_'.join(corruption + [stepsize] + fsplit[-4:-1] ) + '.png'\n",
    "#         os.rename(path+f, path+newf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f4006-5796-4be2-8f74-a696ef9cf580",
   "metadata": {},
   "source": [
    "# generate experiment source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ea933ea-5ca8-4a8e-a693-b7fc777b6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_prac length  10  df_exp length  480\n",
      "['dotted_line' 'fog' 'glass_blur' 'impulse_noise' 'motion_blur'\n",
      " 'shot_noise' 'spatter' 'zigzag']\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# create trial file\n",
    "############################\n",
    "path_exp = './stimuli/stimuli-exp1-step5/'\n",
    "# masklist = ['./stimuli/stimuli-mask/'+f for f in os.listdir('./stimuli/stimuli-mask/') if not f.startswith('.')]\n",
    "masklist = [f for f in os.listdir('./stimuli/stimuli-mask/') if not f.startswith('.')] #when only filenames (not entire path) is used to create source file\n",
    "\n",
    "df = pd.DataFrame(columns=['trialtype', 'corruption',  'cond', 'nstep', 'imgID', 'gt', 'our', 'imgpath', 'maskpath'] )\n",
    "\n",
    "\n",
    "i=1\n",
    "for f in os.listdir(path_exp):\n",
    "    if not f.startswith('.'):\n",
    "        \n",
    "        corruption = '_'.join(f.split('_')[:-4])\n",
    "        if corruption == 'identity': #use as practice trials\n",
    "            trialtype = 'prac'\n",
    "        else:\n",
    "            trialtype = 'exp'\n",
    "        \n",
    "        nstep = int(f.split('_')[-4][-1])\n",
    "        if nstep == 1:\n",
    "            cond = 'low'\n",
    "        elif nstep == 2 or nstep ==3:\n",
    "            cond = 'med'\n",
    "        elif nstep == 4 or nstep ==5:\n",
    "            cond = 'high'\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        imgID = int(f.split('_')[-3][1:])\n",
    "        gt = int(f.split('_')[-2][1:])\n",
    "        our = int(f.split('_')[-1][1])\n",
    "#         imgpath = path_exp + f\n",
    "        imgpath = f\n",
    "        maskpath= random.sample(masklist,1)[0]\n",
    "\n",
    "        df.loc[i] = [trialtype, corruption, cond, nstep, imgID, gt, our, imgpath, maskpath]   \n",
    "        i+=1\n",
    "        \n",
    "df = df.sort_values(by=['trialtype', 'corruption', 'cond']).reset_index(drop=True)\n",
    "df_prac = df[df['trialtype']=='prac'].copy()\n",
    "df_exp = df[df['trialtype']=='exp'].copy()\n",
    "\n",
    "print('df_prac length ', len(df_prac), ' df_exp length ', len(df_exp))\n",
    "print(df_exp.corruption.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b30d3c93-fbc4-4a13-a133-e71ddb02efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# separate exp df into 5 unique sets; 5 sets * 96 images (8corruptions*4high*4med*4low)\n",
    "###############\n",
    "N_SET = 5\n",
    "df_exp['cumcount'] = df_exp.groupby(['corruption', 'cond']).cumcount()+1\n",
    "df_exp['setnum'] = df_exp['cumcount'].apply(lambda x: int(x%N_SET + 1))\n",
    "df_exp = df_exp.drop(columns =['cumcount'])\n",
    "\n",
    "sourcedf_all = []\n",
    "for i in range(1, N_SET+1):\n",
    "    expset = df_exp[df_exp.setnum==i] \n",
    "    expset = expset.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "    combined = df_prac.merge(expset, how='outer') # merge with prac\n",
    "    combined = combined.reset_index(drop=True)\n",
    "    combined['setnum'] = i # since prac parts has no set numbers\n",
    "    sourcedf_all.append(combined)\n",
    "#     combined.to_csv(f'exp1_source{i}.csv', index=False)\n",
    "\n",
    "df_all = pd.concat(sourcedf_all)\n",
    "# print('source csvs are saved to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c56d864-788b-4264-9ad3-4d8a38ecf17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialtype</th>\n",
       "      <th>corruption</th>\n",
       "      <th>cond</th>\n",
       "      <th>nstep</th>\n",
       "      <th>imgID</th>\n",
       "      <th>gt</th>\n",
       "      <th>our</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>maskpath</th>\n",
       "      <th>setnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1770</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>identity_step1_t1770_g7_o7.png</td>\n",
       "      <td>mask_1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>9570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>identity_step1_t9570_g1_o1.png</td>\n",
       "      <td>mask_5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>2114</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>identity_step1_t2114_g5_o5.png</td>\n",
       "      <td>mask_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>4758</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>identity_step1_t4758_g3_o3.png</td>\n",
       "      <td>mask_9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>9397</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>identity_step1_t9397_g9_o9.png</td>\n",
       "      <td>mask_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1202</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>identity_step1_t1202_g8_o8.png</td>\n",
       "      <td>mask_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>5872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>identity_step1_t5872_g1_o1.png</td>\n",
       "      <td>mask_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>6251</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>identity_step1_t6251_g4_o4.png</td>\n",
       "      <td>mask_9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1106</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>identity_step1_t1106_g6_o6.png</td>\n",
       "      <td>mask_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prac</td>\n",
       "      <td>identity</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>3778</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>identity_step2_t3778_g5_o5.png</td>\n",
       "      <td>mask_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exp</td>\n",
       "      <td>glass_blur</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>glass_blur_step5_t2020_g3_o3.png</td>\n",
       "      <td>mask_4.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>exp</td>\n",
       "      <td>fog</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1854</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>fog_step1_t1854_g6_o6.png</td>\n",
       "      <td>mask_4.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>exp</td>\n",
       "      <td>spatter</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>7823</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>spatter_step2_t7823_g8_o8.png</td>\n",
       "      <td>mask_9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>exp</td>\n",
       "      <td>shot_noise</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "      <td>7405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shot_noise_step5_t7405_g1_o1.png</td>\n",
       "      <td>mask_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>exp</td>\n",
       "      <td>zigzag</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>4917</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>zigzag_step3_t4917_g1_o1.png</td>\n",
       "      <td>mask_4.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>exp</td>\n",
       "      <td>shot_noise</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>shot_noise_step1_t4537_g3_o3.png</td>\n",
       "      <td>mask_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>exp</td>\n",
       "      <td>fog</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "      <td>2582</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>fog_step5_t2582_g9_o9.png</td>\n",
       "      <td>mask_1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>exp</td>\n",
       "      <td>spatter</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2689</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>spatter_step2_t2689_g5_o5.png</td>\n",
       "      <td>mask_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>exp</td>\n",
       "      <td>dotted_line</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>7315</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>dotted_line_step1_t7315_g5_o5.png</td>\n",
       "      <td>mask_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>exp</td>\n",
       "      <td>motion_blur</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "      <td>4027</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>motion_blur_step5_t4027_g7_o7.png</td>\n",
       "      <td>mask_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialtype   corruption  cond  nstep  imgID  gt  our  \\\n",
       "0       prac     identity   low      1   1770   7    7   \n",
       "1       prac     identity   low      1   9570   1    1   \n",
       "2       prac     identity   low      1   2114   5    5   \n",
       "3       prac     identity   low      1   4758   3    3   \n",
       "4       prac     identity   low      1   9397   9    9   \n",
       "5       prac     identity   low      1   1202   8    8   \n",
       "6       prac     identity   low      1   5872   1    1   \n",
       "7       prac     identity   low      1   6251   4    4   \n",
       "8       prac     identity   low      1   1106   6    6   \n",
       "9       prac     identity   med      2   3778   5    5   \n",
       "10       exp   glass_blur  high      5   2020   3    3   \n",
       "11       exp          fog   low      1   1854   6    6   \n",
       "12       exp      spatter   med      2   7823   8    8   \n",
       "13       exp   shot_noise  high      5   7405   1    1   \n",
       "14       exp       zigzag   med      3   4917   1    1   \n",
       "15       exp   shot_noise   low      1   4537   3    3   \n",
       "16       exp          fog  high      5   2582   9    9   \n",
       "17       exp      spatter   med      2   2689   5    5   \n",
       "18       exp  dotted_line   low      1   7315   5    5   \n",
       "19       exp  motion_blur  high      5   4027   7    7   \n",
       "\n",
       "                              imgpath    maskpath  setnum  \n",
       "0      identity_step1_t1770_g7_o7.png  mask_1.png       1  \n",
       "1      identity_step1_t9570_g1_o1.png  mask_5.png       1  \n",
       "2      identity_step1_t2114_g5_o5.png  mask_6.png       1  \n",
       "3      identity_step1_t4758_g3_o3.png  mask_9.png       1  \n",
       "4      identity_step1_t9397_g9_o9.png  mask_8.png       1  \n",
       "5      identity_step1_t1202_g8_o8.png  mask_6.png       1  \n",
       "6      identity_step1_t5872_g1_o1.png  mask_8.png       1  \n",
       "7      identity_step1_t6251_g4_o4.png  mask_9.png       1  \n",
       "8      identity_step1_t1106_g6_o6.png  mask_6.png       1  \n",
       "9      identity_step2_t3778_g5_o5.png  mask_3.png       1  \n",
       "10   glass_blur_step5_t2020_g3_o3.png  mask_4.png       1  \n",
       "11          fog_step1_t1854_g6_o6.png  mask_4.png       1  \n",
       "12      spatter_step2_t7823_g8_o8.png  mask_9.png       1  \n",
       "13   shot_noise_step5_t7405_g1_o1.png  mask_6.png       1  \n",
       "14       zigzag_step3_t4917_g1_o1.png  mask_4.png       1  \n",
       "15   shot_noise_step1_t4537_g3_o3.png  mask_7.png       1  \n",
       "16          fog_step5_t2582_g9_o9.png  mask_1.png       1  \n",
       "17      spatter_step2_t2689_g5_o5.png  mask_3.png       1  \n",
       "18  dotted_line_step1_t7315_g5_o5.png  mask_8.png       1  \n",
       "19  motion_blur_step5_t4027_g7_o7.png  mask_6.png       1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb3f2904-d13a-4b1f-a9c2-6c6de85e8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('./stimuli/datasource-exp1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0988c1b4-7b82-4241-bde4-a2507deb7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# how many unique images overlap?\n",
    "######\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv('./stimuli/datasource-exp1.csv')\n",
    "df_exp = df_all[df_all['trialtype']=='exp']\n",
    "# df_exp.imgID.nunique() #449\n",
    "# len(df_exp.imgID) # 480 --> 31 overlap, making 6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
