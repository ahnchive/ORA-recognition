{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set current directory (where this repo is located)\n",
    "import os\n",
    "PROJECT_ROOT = '/home/young/workspace/reconstruction/recon-mnistc'\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print('current directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fb84ac-07b8-45af-b916-291e81918290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization import *\n",
    "from ourmodel import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "N_MINI_PER_CORRUPTION = 1000\n",
    "\n",
    "ACC_TYPE = \"entropy\"\n",
    "\n",
    "# general helper funtions for model testing\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_batch(task, batchnum, model, args, train=False, verbose=True, onlyacc=False):\n",
    "    \n",
    "    # evaluate on one train/test batch \n",
    "    model.eval()\n",
    "    \n",
    "    if task == 'mnist_recon':\n",
    "        # for mnist recon data, it has erased input(x) and intact input (gtx)\n",
    "        if train:\n",
    "            dataloader, val_dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train)\n",
    "        else:\n",
    "            dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train)            \n",
    "        diter = iter(dataloader)\n",
    "        for i in range(batchnum):\n",
    "            x, gtx, y = next(diter)\n",
    "    else:\n",
    "        dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train)    \n",
    "        diter = iter(dataloader)\n",
    "        for i in range(batchnum):\n",
    "            x, y = next(diter)\n",
    "            gtx = None\n",
    "            \n",
    "            \n",
    "    # attach forward hooks for intermediate outputs for visualizations\n",
    "    outputs = {}\n",
    "    \n",
    "    # from model main output\n",
    "    x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "    \n",
    "    # from model dynamic routing\n",
    "    coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "    outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "    def get_attention_outputs():\n",
    "        def hook(model, input, output):\n",
    "            x_mask_step.append(output[0].detach())\n",
    "            x_input_step.append(output[1].detach())\n",
    "        return hook\n",
    "\n",
    "    def get_capsule_outputs():\n",
    "        def hook(model, input, output):\n",
    "            objcaps_step.append(output[0].detach())\n",
    "            coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "            betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "            if 'rscores' in output[1].keys():\n",
    "                rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "            if 'recon_coups' in output[1].keys():\n",
    "                recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "            if 'outcaps_len' in output[1].keys():\n",
    "                outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "            if 'outcaps_len_before' in output[1].keys():\n",
    "                outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "        return hook\n",
    "    \n",
    "\n",
    "    hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "    hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "    \n",
    "    # evaluate and detach hooks\n",
    "    losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "    hook1.remove()\n",
    "    hook2.remove()\n",
    "    \n",
    "    # add tensor outputs dictionary\n",
    "    outputs['x_input'] = torch.stack(x_input_step, dim=1)\n",
    "    outputs['x_mask'] = torch.stack(x_mask_step, dim=1)\n",
    "    outputs['objcaps'] = torch.stack(objcaps_step, dim=1)\n",
    "    \n",
    "    outputs['coups'] = torch.stack(coups_step, dim=1)\n",
    "    outputs['betas'] = torch.stack(betas_step, dim=1)\n",
    "    if rscores_step:\n",
    "        outputs['rscores'] = torch.stack(rscores_step, dim=1)\n",
    "    if recon_coups_step:\n",
    "        outputs['recon_coups'] = torch.stack(recon_coups_step, dim=1)\n",
    "    if outcaps_len_step:\n",
    "        outputs['outcaps_len'] = torch.stack(outcaps_len_step, dim=1)\n",
    "    if outcaps_len_before_step:\n",
    "        outputs['outcaps_len_before'] = torch.stack(outcaps_len_before_step, dim=1)        \n",
    "    if verbose:\n",
    "        print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (losses[0], losses[1], losses[2], acc))\n",
    "    \n",
    "    if onlyacc:\n",
    "        return acc\n",
    "    else:\n",
    "        return x, gtx, y, objcaps_len_step, x_recon_step, outputs\n",
    "    \n",
    "\n",
    "###########################\n",
    "# evaluate on mnist-mini version\n",
    "############################\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_mini(corruption, model, args, train=False, verbose=True, save_hooks=False, max_batch_num=None):\n",
    "    \n",
    "    model.eval()  \n",
    "    \n",
    "    # get corruption batch information\n",
    "    corruption_id = int(CORRUPTION_TYPES.index(corruption))\n",
    "    num_batch_required = int(N_MINI_PER_CORRUPTION/BATCHSIZE) # if batchsize 100; 10 batches are requried\n",
    "    \n",
    "    # load dataloader and iterator\n",
    "    dataloader = fetch_dataloader('mnist_c_mini', DATA_DIR, DEVICE, BATCHSIZE, train)    \n",
    "    diter = iter(dataloader)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "          \n",
    "    # get input and gt\n",
    "    for i in range(corruption_id*num_batch_required): #id =0, 0 iteration; id=1, 10 iteration\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "    \n",
    "    for i in range(0, num_batch_required):\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "            \n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "            \n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "        \n",
    "        if save_hooks:\n",
    "        \n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_mini(corruption, cnn, max_batch_num=None):\n",
    "    cnn.eval() \n",
    "    \n",
    "    # get corruption batch information\n",
    "    corruption_id = int(CORRUPTION_TYPES.index(corruption))\n",
    "    num_batch_required = int(N_MINI_PER_CORRUPTION/BATCHSIZE) # if batchsize 100; 10 batches are requried\n",
    "    \n",
    "    # load dataloader and iterator\n",
    "    dataloader = fetch_dataloader('mnist_c_mini', DATA_DIR, DEVICE, BATCHSIZE, train=False)    \n",
    "    diter = iter(dataloader)\n",
    "    \n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "    \n",
    "\n",
    "    # get input and gt\n",
    "    for i in range(corruption_id*num_batch_required): #id =0, 0 iteration; id=1, 10 iteration\n",
    "        x, y = next(diter)\n",
    "    \n",
    "\n",
    "    for i in range(0, num_batch_required):\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "        \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "        \n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "    \n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all\n",
    "\n",
    "###########################\n",
    "# evaluate on mnist-c original version\n",
    "############################\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False,  batch_num=None):\n",
    "    model.eval() \n",
    "    \n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "    \n",
    "         \n",
    "    \n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        i+=1        \n",
    "        \n",
    "#         if max_batch_num:\n",
    "#             if i == max_batch_num:\n",
    "#                 break\n",
    "                \n",
    "        if i == batch_num:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "\n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_original(corruption, cnn, batch_num=None):\n",
    "    cnn.eval() \n",
    "\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "\n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        i+=1        \n",
    "#         if max_batch_num:\n",
    "#             if i == max_batch_num:\n",
    "#                 break\n",
    "\n",
    "        if i == batch_num:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "                    \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "\n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_expstimuli(expname, model, args, verbose=True, save_hooks=False):\n",
    "    \n",
    "    model.eval()  \n",
    "    \n",
    "    # get corruption batch information\n",
    "#     corruption_id = int(CORRUPTION_TYPES.index(corruption))\n",
    "#     num_batch_required = int(N_MINI_PER_CORRUPTION/BATCHSIZE) # if batchsize 100; 10 batches are requried\n",
    "    \n",
    "    # load dataloader and iterator\n",
    "    dataloader = fetch_dataloader(expname, DATA_DIR, DEVICE, BATCHSIZE, train)    \n",
    "    diter = iter(dataloader)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "          \n",
    "    \n",
    "    for i in range(0, len(diter)):\n",
    "        x, y = next(diter)\n",
    "        gtx = None\n",
    "            \n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc.mean()))   \n",
    "            \n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "        \n",
    "        if save_hooks:\n",
    "        \n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec438cb6-ac3a-4056-8ecd-d76c1403ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute stepwise entropy\n",
    "from torch.distributions import Categorical\n",
    "from copy import deepcopy\n",
    "\n",
    "def count_changes(outputs):\n",
    "\n",
    "    # copy capslen\n",
    "    capslen = deepcopy(outputs['outcaps_len'])\n",
    "    T=0.2\n",
    "    capslen = F.softmax(capslen/T, dim=-1)\n",
    "    print(capslen.shape)\n",
    "\n",
    "    # get entropy\n",
    "    dist = Categorical(probs=capslen)\n",
    "    entropy = dist.entropy()\n",
    "    print(entropy.shape)\n",
    "\n",
    "    # get nstep\n",
    "    threshold=0.6\n",
    "    bools = (entropy.view(len(entropy),-1)<threshold)*1\n",
    "    # bools[:,0:2]=-99\n",
    "    # get first true index along second axis\n",
    "    index = bools.argmax(dim=1)\n",
    "\n",
    "    # set index to 14 for rows with all false values\n",
    "    # mask = bools.sum(dim=1) == -99*2\n",
    "    mask = bools.sum(dim=1) == 0\n",
    "\n",
    "    index[mask] = 14\n",
    "    print(index.shape)\n",
    "    \n",
    "    # get match variables (ylabel == argmax out label)\n",
    "    yindex_expanded = y.argmax(dim=-1).unsqueeze(1).unsqueeze(2).cpu()\n",
    "    outindex = outputs['outcaps_len'].argmax(dim=-1).cpu()\n",
    "    match = torch.eq(outindex, yindex_expanded)\n",
    "\n",
    "    mask_f2tlist, mask_t2flist, mask_atlist, mask_aflist = [[] for i in range(4)]\n",
    "    f2tlist, t2flist, atlist, aflist, totallist = [[] for i in range(5)]\n",
    "\n",
    "    for i, marray in enumerate(match):\n",
    "\n",
    "        nallstep = index[i]\n",
    "        nmaskstep = int(nallstep/3)\n",
    "        marray_trim = marray[:nmaskstep+1]\n",
    "        mask_iter_results = marray_trim[:,-1]\n",
    "\n",
    "        mask_false2true = 1 if (mask_iter_results[0] == False) and (mask_iter_results[-1] == True) else 0\n",
    "        mask_true2false = 1 if (mask_iter_results[0] == True) and (mask_iter_results[-1] == False) else 0\n",
    "        mask_alltrue = 1 if torch.all(mask_iter_results) else 0\n",
    "        mask_allfalse = 1 if torch.all(torch.logical_not(mask_iter_results)) else 0\n",
    "        mask_f2tlist.append(mask_false2true)\n",
    "        mask_t2flist.append(mask_true2false)\n",
    "        mask_atlist.append(mask_alltrue)\n",
    "        mask_aflist.append(mask_allfalse)        \n",
    "        \n",
    "        # features \n",
    "        false2true = 0\n",
    "        true2false = 0 \n",
    "        alltrue = 0\n",
    "        allfalse = 0\n",
    "        total = len(marray_trim)\n",
    "\n",
    "        for m in marray_trim:\n",
    "            if (m[0] == False) and (m[-1] == True):\n",
    "                false2true += 1\n",
    "            elif (m[0] == True) and (m[-1] == False):\n",
    "                true2false += 1\n",
    "            elif torch.all(m):\n",
    "                alltrue += 1\n",
    "            elif torch.all(torch.logical_not(m)):\n",
    "                allfalse += 1\n",
    "\n",
    "\n",
    "        f2tlist.append(false2true)\n",
    "        t2flist.append(true2false)\n",
    "        atlist.append(alltrue)\n",
    "        aflist.append(allfalse)\n",
    "        totallist.append(total)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['mask_false2true'] = mask_f2tlist\n",
    "    df['mask_true2false'] = mask_t2flist\n",
    "    df['mask_alltrue'] = mask_atlist\n",
    "    df['mask_allfalse'] = mask_aflist\n",
    "    df['feature_false2true'] = f2tlist\n",
    "    df['feature_true2false'] = t2flist\n",
    "    df['feature_alltrue'] = atlist\n",
    "    df['feature_allfalse'] = aflist\n",
    "    df['nstep'] = totallist\n",
    "\n",
    "    mask_percent_f2t = len(df[df['mask_false2true']>0])/len(df)\n",
    "    mask_percent_t2f = len(df[df['mask_true2false']>0])/len(df)\n",
    "    mask_percent_at = len(df[df['mask_alltrue']>0])/len(df)\n",
    "    mask_percent_af = len(df[df['mask_allfalse']>0])/len(df)\n",
    "    \n",
    "    print(\"percent changes by spatial mask\") # average over trials\n",
    "    print(f'false2true %, {mask_percent_f2t}')     \n",
    "    print(f'true2false %, {mask_percent_t2f}')     \n",
    "    print(f'all true%, {mask_percent_at}')     \n",
    "    print(f'all false %, {mask_percent_af}')  \n",
    "    \n",
    "    print(\"percent changes by feature binding\") # average by number of steps per each trial, then average over trials\n",
    "    feature_percent_f2t = (df['feature_false2true']/df['nstep']).mean()\n",
    "    feature_percent_t2f = (df['feature_true2false']/df['nstep']).mean()\n",
    "    feature_percent_at = (df['feature_alltrue']/df['nstep']).mean()\n",
    "    feature_percent_af = (df['feature_allfalse']/df['nstep']).mean()\n",
    "    \n",
    "    print(f'false2true %, {feature_percent_f2t}')     \n",
    "    print(f'true2false %, {feature_percent_t2f}')     \n",
    "    print(f'all true%, {feature_percent_at}')     \n",
    "    print(f'all false %, {feature_percent_af}')  \n",
    "    \n",
    "    return mask_percent_f2t, mask_percent_t2f, mask_percent_at, mask_percent_af, \\\n",
    "            feature_percent_f2t, feature_percent_t2f, feature_percent_at, feature_percent_af\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5036c033-a8b2-40e5-bad5-743112b65435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 5\n",
      "ENCODER: resnet w/ None projection\n",
      "...resulting primary caps #: 288, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "model is loaded from ./models/our-resnet/run1.pt\n",
      "\n",
      "\n",
      "===========identity==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.0\n",
      "true2false %, 0.001\n",
      "all true%, 0.994\n",
      "all false %, 0.005\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0\n",
      "true2false %, 0.0002\n",
      "all true%, 0.9945\n",
      "all false %, 0.0053\n",
      "\n",
      "\n",
      "===========shot_noise==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.002\n",
      "true2false %, 0.014\n",
      "all true%, 0.972\n",
      "all false %, 0.011\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0012333333333333335\n",
      "true2false %, 0.0005\n",
      "all true%, 0.9777500000000003\n",
      "all false %, 0.02051666666666667\n",
      "\n",
      "\n",
      "===========impulse_noise==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.034\n",
      "true2false %, 0.007\n",
      "all true%, 0.93\n",
      "all false %, 0.026\n",
      "percent changes by feature binding\n",
      "false2true %, 0.005733333333333334\n",
      "true2false %, 0.0034000000000000002\n",
      "all true%, 0.9476333333333332\n",
      "all false %, 0.04278333333333335\n",
      "\n",
      "\n",
      "===========glass_blur==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.008\n",
      "true2false %, 0.007\n",
      "all true%, 0.934\n",
      "all false %, 0.049\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0034000000000000002\n",
      "true2false %, 0.0\n",
      "all true%, 0.9393666666666667\n",
      "all false %, 0.0567\n",
      "\n",
      "\n",
      "===========motion_blur==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.006\n",
      "true2false %, 0.007\n",
      "all true%, 0.959\n",
      "all false %, 0.025\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0013333333333333333\n",
      "true2false %, 0.0005\n",
      "all true%, 0.9654333333333334\n",
      "all false %, 0.032733333333333337\n",
      "\n",
      "\n",
      "===========shear==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.003\n",
      "true2false %, 0.002\n",
      "all true%, 0.983\n",
      "all false %, 0.012\n",
      "percent changes by feature binding\n",
      "false2true %, 0.00045\n",
      "true2false %, 0.0002\n",
      "all true%, 0.9851499999999999\n",
      "all false %, 0.014199999999999999\n",
      "\n",
      "\n",
      "===========scale==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.001\n",
      "true2false %, 0.002\n",
      "all true%, 0.969\n",
      "all false %, 0.027\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0002\n",
      "true2false %, 0.001\n",
      "all true%, 0.9713999999999999\n",
      "all false %, 0.027399999999999997\n",
      "\n",
      "\n",
      "===========rotate==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.003\n",
      "true2false %, 0.002\n",
      "all true%, 0.933\n",
      "all false %, 0.06\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0025\n",
      "true2false %, 0.0032\n",
      "all true%, 0.9342333333333335\n",
      "all false %, 0.05966666666666667\n",
      "\n",
      "\n",
      "===========brightness==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.147\n",
      "true2false %, 0.001\n",
      "all true%, 0.841\n",
      "all false %, 0.009\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0095\n",
      "true2false %, 0.015033333333333333\n",
      "all true%, 0.9075333333333331\n",
      "all false %, 0.06523333333333335\n",
      "\n",
      "\n",
      "===========translate==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.021\n",
      "true2false %, 0.083\n",
      "all true%, 0.566\n",
      "all false %, 0.318\n",
      "percent changes by feature binding\n",
      "false2true %, 0.006100000000000001\n",
      "true2false %, 0.018833333333333327\n",
      "all true%, 0.6081\n",
      "all false %, 0.36636666666666684\n",
      "\n",
      "\n",
      "===========stripe==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.153\n",
      "true2false %, 0.014\n",
      "all true%, 0.741\n",
      "all false %, 0.088\n",
      "percent changes by feature binding\n",
      "false2true %, 0.011\n",
      "true2false %, 0.028233333333333326\n",
      "all true%, 0.821733333333333\n",
      "all false %, 0.1375833333333333\n",
      "\n",
      "\n",
      "===========fog==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.401\n",
      "true2false %, 0.002\n",
      "all true%, 0.57\n",
      "all false %, 0.02\n",
      "percent changes by feature binding\n",
      "false2true %, 0.007316666666666666\n",
      "true2false %, 0.011933333333333334\n",
      "all true%, 0.7720833333333335\n",
      "all false %, 0.20625\n",
      "\n",
      "\n",
      "===========spatter==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.006\n",
      "true2false %, 0.005\n",
      "all true%, 0.976\n",
      "all false %, 0.011\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0007333333333333333\n",
      "true2false %, 0.0004\n",
      "all true%, 0.9820333333333332\n",
      "all false %, 0.016633333333333333\n",
      "\n",
      "\n",
      "===========dotted_line==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.008\n",
      "true2false %, 0.004\n",
      "all true%, 0.975\n",
      "all false %, 0.012\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0017333333333333333\n",
      "true2false %, 0.0002\n",
      "all true%, 0.9794333333333333\n",
      "all false %, 0.01863333333333333\n",
      "\n",
      "\n",
      "===========zigzag==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.033\n",
      "true2false %, 0.004\n",
      "all true%, 0.903\n",
      "all false %, 0.06\n",
      "percent changes by feature binding\n",
      "false2true %, 0.004383333333333333\n",
      "true2false %, 0.0008\n",
      "all true%, 0.9187166666666666\n",
      "all false %, 0.07560000000000001\n",
      "\n",
      "\n",
      "===========canny_edges==========\n",
      "torch.Size([1000, 5, 3, 10])\n",
      "torch.Size([1000, 5, 3])\n",
      "torch.Size([1000])\n",
      "percent changes by spatial mask\n",
      "false2true %, 0.011\n",
      "true2false %, 0.023\n",
      "all true%, 0.735\n",
      "all false %, 0.217\n",
      "percent changes by feature binding\n",
      "false2true %, 0.0048000000000000004\n",
      "true2false %, 0.005300000000000001\n",
      "all true%, 0.7520333333333333\n",
      "all false %, 0.23706666666666676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corruption</th>\n",
       "      <th>mask_f2t</th>\n",
       "      <th>mask_t2f</th>\n",
       "      <th>mask_at</th>\n",
       "      <th>mask_af</th>\n",
       "      <th>feature_f2t</th>\n",
       "      <th>feature_t2f</th>\n",
       "      <th>feature_at</th>\n",
       "      <th>feature_af</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identity</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.994500</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shot_noise</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.977750</td>\n",
       "      <td>0.020517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impulse_noise</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.947633</td>\n",
       "      <td>0.042783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glass_blur</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939367</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>motion_blur</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.965433</td>\n",
       "      <td>0.032733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shear</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.985150</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scale</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rotate</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.934233</td>\n",
       "      <td>0.059667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brightness</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.907533</td>\n",
       "      <td>0.065233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>translate</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.366367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stripe</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.028233</td>\n",
       "      <td>0.821733</td>\n",
       "      <td>0.137583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fog</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>0.772083</td>\n",
       "      <td>0.206250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spatter</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.016633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dotted_line</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>0.018633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.918717</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>canny_edges</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.752033</td>\n",
       "      <td>0.237067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corruption  mask_f2t  mask_t2f  mask_at  mask_af  feature_f2t  \\\n",
       "0        identity     0.000     0.001    0.994    0.005     0.000000   \n",
       "1      shot_noise     0.002     0.014    0.972    0.011     0.001233   \n",
       "2   impulse_noise     0.034     0.007    0.930    0.026     0.005733   \n",
       "3      glass_blur     0.008     0.007    0.934    0.049     0.003400   \n",
       "4     motion_blur     0.006     0.007    0.959    0.025     0.001333   \n",
       "5           shear     0.003     0.002    0.983    0.012     0.000450   \n",
       "6           scale     0.001     0.002    0.969    0.027     0.000200   \n",
       "7          rotate     0.003     0.002    0.933    0.060     0.002500   \n",
       "8      brightness     0.147     0.001    0.841    0.009     0.009500   \n",
       "9       translate     0.021     0.083    0.566    0.318     0.006100   \n",
       "10         stripe     0.153     0.014    0.741    0.088     0.011000   \n",
       "11            fog     0.401     0.002    0.570    0.020     0.007317   \n",
       "12        spatter     0.006     0.005    0.976    0.011     0.000733   \n",
       "13    dotted_line     0.008     0.004    0.975    0.012     0.001733   \n",
       "14         zigzag     0.033     0.004    0.903    0.060     0.004383   \n",
       "15    canny_edges     0.011     0.023    0.735    0.217     0.004800   \n",
       "\n",
       "    feature_t2f  feature_at  feature_af  \n",
       "0      0.000200    0.994500    0.005300  \n",
       "1      0.000500    0.977750    0.020517  \n",
       "2      0.003400    0.947633    0.042783  \n",
       "3      0.000000    0.939367    0.056700  \n",
       "4      0.000500    0.965433    0.032733  \n",
       "5      0.000200    0.985150    0.014200  \n",
       "6      0.001000    0.971400    0.027400  \n",
       "7      0.003200    0.934233    0.059667  \n",
       "8      0.015033    0.907533    0.065233  \n",
       "9      0.018833    0.608100    0.366367  \n",
       "10     0.028233    0.821733    0.137583  \n",
       "11     0.011933    0.772083    0.206250  \n",
       "12     0.000400    0.982033    0.016633  \n",
       "13     0.000200    0.979433    0.018633  \n",
       "14     0.000800    0.918717    0.075600  \n",
       "15     0.005300    0.752033    0.237067  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# model comparison on a single batch \n",
    "# (if tested on mnist_c_mini, all different corruption type batches are tested)\n",
    "##################\n",
    "\n",
    "CORRUPTION_TYPE_INTEREST = [\n",
    "         'glass_blur','motion_blur', 'impulse_noise','shot_noise',\n",
    "        'fog','dotted_line','spatter', 'zigzag']\n",
    "\n",
    "task='mnist_c_mini' # 'mnist_occlusion', 'mnist_recon'\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings':3 , 'mask_threshold': 0.1}\n",
    "\n",
    "\n",
    "# modellist = [\n",
    "\n",
    "# # './results/mnist/Aug14_0525_hsf_res4_run2/best_epoch25_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0508_lsf_res4_run1/best_epoch30_acc1.0000.pt'\n",
    "# # './results/mnist/Aug14_0524_lsf_res4_run2/best_epoch29_acc1.0000.pt'\n",
    "# # './results/mnist/Aug14_0805_lsf_conv_run5/best_epoch88_acc0.9988.pt',\n",
    "\n",
    "# ]\n",
    "\n",
    "modellist = ['./models/our-resnet/run1.pt']\n",
    "\n",
    "resdf = pd.DataFrame()\n",
    "for i, load_model_path in enumerate(modellist):\n",
    "    \n",
    "    # load model\n",
    "    args = load_args(load_model_path, args_to_update, print_args)\n",
    "    model = load_model(args)\n",
    "    print(f'model is loaded from {load_model_path}')\n",
    "\n",
    "    if task=='mnist_c_mini':\n",
    "        resdf['corruption'] = CORRUPTION_TYPES\n",
    "#         accs = []\n",
    "        for ci, corruption in enumerate(CORRUPTION_TYPES):\n",
    "            print(f'\\n\\n==========={corruption}==========')\n",
    "            x, gtx, y, acc_all, objcaps_len_step, x_recon_step, outputs = \\\n",
    "            evaluate_model_on_mnistc_mini(corruption, model, args, train, verbose=False, save_hooks=True)\n",
    "#             accs.append(acc_all.mean().item())\n",
    "            \n",
    "            mask_percent_f2t, mask_percent_t2f, mask_percent_at, mask_percent_af, \\\n",
    "            feature_percent_f2t, feature_percent_t2f, feature_percent_at, feature_percent_af = count_changes(outputs)\n",
    "            \n",
    "            resdf.loc[ci, 'mask_f2t'] = mask_percent_f2t\n",
    "            resdf.loc[ci, 'mask_t2f'] = mask_percent_t2f\n",
    "            resdf.loc[ci, 'mask_at'] = mask_percent_at\n",
    "            resdf.loc[ci, 'mask_af'] = mask_percent_af\n",
    "            \n",
    "            resdf.loc[ci, 'feature_f2t'] = feature_percent_f2t\n",
    "            resdf.loc[ci, 'feature_t2f'] = feature_percent_t2f\n",
    "            resdf.loc[ci, 'feature_at'] = feature_percent_at\n",
    "            resdf.loc[ci, 'feature_af'] = feature_percent_af\n",
    "            \n",
    "            \n",
    "resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad6922e4-3eb0-42cf-9ba1-b7a19dd5d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files\n",
    "resdf.to_csv('results/changes_in_hypothesis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df391098-7970-4dc2-87b8-0febbd7b100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1767003/1179611508.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  resdf[resdf['corruption'].isin(CORRUPTION_TYPE_INTEREST)].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mask_f2t       0.062250\n",
       "mask_t2f       0.006250\n",
       "mask_at        0.902375\n",
       "mask_af        0.026750\n",
       "feature_f2t    0.003233\n",
       "feature_t2f    0.002217\n",
       "feature_at     0.935306\n",
       "feature_af     0.058731\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf[resdf['corruption'].isin(CORRUPTION_TYPE_INTEREST)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c269f844-8fe0-4eb5-afbb-f0cee86e2983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corruption</th>\n",
       "      <th>mask_f2t</th>\n",
       "      <th>mask_t2f</th>\n",
       "      <th>mask_at</th>\n",
       "      <th>mask_af</th>\n",
       "      <th>feature_f2t</th>\n",
       "      <th>feature_t2f</th>\n",
       "      <th>feature_at</th>\n",
       "      <th>feature_af</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shot_noise</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.977750</td>\n",
       "      <td>0.020517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impulse_noise</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.947633</td>\n",
       "      <td>0.042783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glass_blur</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939367</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>motion_blur</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.965433</td>\n",
       "      <td>0.032733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fog</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>0.772083</td>\n",
       "      <td>0.206250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spatter</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.016633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dotted_line</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>0.018633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.918717</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corruption  mask_f2t  mask_t2f  mask_at  mask_af  feature_f2t  \\\n",
       "1      shot_noise     0.002     0.014    0.972    0.011     0.001233   \n",
       "2   impulse_noise     0.034     0.007    0.930    0.026     0.005733   \n",
       "3      glass_blur     0.008     0.007    0.934    0.049     0.003400   \n",
       "4     motion_blur     0.006     0.007    0.959    0.025     0.001333   \n",
       "11            fog     0.401     0.002    0.570    0.020     0.007317   \n",
       "12        spatter     0.006     0.005    0.976    0.011     0.000733   \n",
       "13    dotted_line     0.008     0.004    0.975    0.012     0.001733   \n",
       "14         zigzag     0.033     0.004    0.903    0.060     0.004383   \n",
       "\n",
       "    feature_t2f  feature_at  feature_af  \n",
       "1      0.000500    0.977750    0.020517  \n",
       "2      0.003400    0.947633    0.042783  \n",
       "3      0.000000    0.939367    0.056700  \n",
       "4      0.000500    0.965433    0.032733  \n",
       "11     0.011933    0.772083    0.206250  \n",
       "12     0.000400    0.982033    0.016633  \n",
       "13     0.000200    0.979433    0.018633  \n",
       "14     0.000800    0.918717    0.075600  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf[resdf['corruption'].isin(CORRUPTION_TYPE_INTEREST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16e99e-47cb-4b4f-b9b1-80de75f785a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
