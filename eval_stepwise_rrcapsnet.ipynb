{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47b1d691-6f9e-4d73-ad35-e725de8c9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization import *\n",
    "from rrcapsnet_original import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "\n",
    "\n",
    "ACC_TYPE = \"entropy\"\n",
    "\n",
    "#################\n",
    "# model load\n",
    "################\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "def recon_loss_step(x_recon_step, x, time_steps):\n",
    "    '''\n",
    "    mse loss is used for reconstruction loss over all steps\n",
    "    '''\n",
    "    losses= []\n",
    "    for t in range(time_steps):\n",
    "        x_recon= x_recon_step[:,t]\n",
    "        ls = nn.MSELoss(reduction='none')(x_recon, x) # 1000, 1, 28, 28\n",
    "        ls = ls.flatten(start_dim=1)\n",
    "        ls = ls.mean(dim=1)\n",
    "        losses.append(ls)\n",
    "        \n",
    "    return torch.stack(losses, dim=1) # 1000 x 5\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_original(corruption, model, max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "    \n",
    "    losses_all, objcaps_len_step_all, acc_all = [],[], []\n",
    "    \n",
    "    model.eval()      \n",
    "    \n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        # evaluate and append results \n",
    "        loss, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "\n",
    "        # append loss and objcaps prediction \n",
    "        losses = recon_loss_step(x_recon_step, x.to(x_recon_step.device), objcaps_len_step.shape[1])\n",
    "\n",
    "        losses_all.append(losses)\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    # concat and add to outputs dictionary\n",
    "    losses_all = torch.cat(losses_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "\n",
    "    return objcaps_len_step_all, losses_all, acc_all\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83c1b61a-7b8f-4b50-b99c-92a3caea9811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis on  fog\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 5\n",
      "ENCODER: resnet w/ None projection\n",
      "...resulting primary caps #: 288, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "original is used\n",
      "==> corruption type: fog, this batch acc: 0.9733999967575073\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# arguments to change\n",
    "#############################\n",
    "\n",
    "# task and dataset\n",
    "task='mnist_c_original'\n",
    "\n",
    "train=False #train or test dataset\n",
    "\n",
    "corruption_index =12\n",
    "corruption =CORRUPTION_TYPES[corruption_index-1]\n",
    "print('analysis on ', corruption)\n",
    "\n",
    "# model and args load\n",
    "print_args=False\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings': 3, 'mask_threshold': 0.1}\n",
    "\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt'\n",
    "load_model_path = './results/mnist/May25_2049_recon_edge_run1/best_epoch68_acc0.9980.pt'\n",
    "load_model_path= './results/mnist/May25_2131_recon_edge_run3/best_epoch70_acc0.9987.pt'\n",
    "load_model_path = './results/mnist/May29_2045_blur_res4_run1/best_epoch32_acc1.0000.pt'\n",
    "load_model_path = './results/mnist/Aug14_0524_lsf_res4_run2/best_epoch29_acc1.0000.pt'\n",
    "load_model_path = './results/mnist/Aug14_0508_lsf_res4_run1/best_epoch30_acc1.0000.pt'\n",
    "\n",
    "###############################\n",
    "# load model and model output\n",
    "###############################\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "# 10000 samples per corruption\n",
    "print(\"original is used\")\n",
    "objcaps_len_step, losses, acc = \\\n",
    "evaluate_model_on_mnistc_original(corruption, model, max_batch_num=None)\n",
    "print(f'==> corruption type: {corruption}, this batch acc: {acc.mean().item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbec22-e42a-4ce3-a591-ba228648e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################    \n",
    "# model entropy stepwise\n",
    "##################################\n",
    "objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "# pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "acc_model_check, pred_model, nstep, no_stop_condition, entropy_model =compute_entropy_based_acc(objcaps_len_step_narrow, y_hot, threshold=0.6, use_cumulative = False, only_acc= False)\n",
    "\n",
    "assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
