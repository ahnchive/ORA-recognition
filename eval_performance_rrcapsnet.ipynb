{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfb98a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization import *\n",
    "from rrcapsnet_original import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "\n",
    "\n",
    "ACC_TYPE = \"hypothesis\"\n",
    "\n",
    "#################\n",
    "# model load\n",
    "################\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "############\n",
    "# testing \n",
    "############\n",
    "def test_model(task, model, args, verbose=False):\n",
    "    # set task and print setting\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    \n",
    "    # get test results\n",
    "    model.eval()\n",
    "    test_dataloader = fetch_dataloader(task, DATA_DIR, DEVICE, BATCHSIZE, train=False)\n",
    "    test_loss, test_loss_class, test_loss_recon, test_acc = test(model, test_dataloader, args, acc_type=ACC_TYPE)\n",
    "    if verbose:\n",
    "        print(\"==> test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (test_loss, test_loss_class, test_loss_recon, test_acc))\n",
    "    return test_loss, test_loss_class, test_loss_recon, test_acc\n",
    "\n",
    "def test_model_mnistc(path_mnistc, corruptionlist, model, verbose=False):\n",
    "    # set task and print setting\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    \n",
    "    # get average test results over corruptionlist   \n",
    "    losses, classlosses, reconlosses, accs = [], [], [], []\n",
    "    for corruption in corruptionlist:\n",
    "        test_loss, test_loss_class, test_loss_recon, test_acc = test_model_on_each_corruption(path_mnistc, corruption, model, verbose)\n",
    "\n",
    "        losses.append(test_loss)\n",
    "        classlosses.append(test_loss_class)\n",
    "        reconlosses.append(test_loss_recon)\n",
    "        accs.append(test_acc)\n",
    "    \n",
    "    avgtest_loss = sum(losses)/len(corruptionlist)\n",
    "    avgtest_loss_class = sum(classlosses)/len(corruptionlist)\n",
    "    avgtest_loss_recon = sum(reconlosses)/len(corruptionlist)\n",
    "    avgtest_acc = sum(accs)/len(corruptionlist)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"==> average test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (avgtest_loss, avgtest_loss_class, avgtest_loss_recon, avgtest_acc))\n",
    "        \n",
    "    return avgtest_loss, avgtest_loss_class, avgtest_loss_recon, avgtest_acc\n",
    "    \n",
    "    \n",
    "def test_model_on_each_corruption(path_mnistc, corruption, model, verbose=False):\n",
    "    path_images = os.path.join(path_mnistc, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(path_mnistc, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # test on the dataloder\n",
    "    model.eval()\n",
    "    test_loss, test_loss_class, test_loss_recon, test_acc = test(model, dataloader, args, acc_type=ACC_TYPE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"==> individual test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "              % (test_loss, test_loss_class, test_loss_recon, test_acc))\n",
    "    return test_loss, test_loss_class, test_loss_recon, test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e00f3-a82c-48ac-913a-bdf4e7364432",
   "metadata": {},
   "source": [
    "# On original MNIST-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e35228f-6fa7-4b15-9b33-8440a9874f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test starts on best_epoch88_acc0.9988.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 1\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n",
      "test starts on best_epoch86_acc0.9982.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 1\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# best model comparison on entire corruptions\n",
    "########################################################\n",
    "verbose=False\n",
    "print_args =False\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 1, 'routings': 1, 'mask_threshold': 0.1}\n",
    "\n",
    "\n",
    "modelpathlist = [\n",
    "# './models/rrcapsnet/run1_epoch50_acc0.9917.pt',\n",
    "# './models/rrcapsnet/run2_epoch50_acc0.9915.pt',\n",
    "# './models/rrcapsnet/run3_epoch50_acc0.9907.pt',\n",
    "# './models/rrcapsnet/run4_epoch50_acc0.9905.pt',\n",
    "# './models/rrcapsnet/run5_epoch50_acc0.9907.pt',\n",
    "\n",
    "# './results/mnist/Apr28_1352_adam_clr_128/archive_model_epoch50_acc0.9987.pt'\n",
    "# './results/mnist/Apr28_1408_adam_clr_512/archive_model_epoch50_acc0.9953.pt' # increase bn worse\n",
    "# './results/mnist/Apr28_1438_adam_clr_128_wde5/archive_model_epoch50_acc0.9986.pt'\n",
    "# './results/mnist/Apr28_1458_adam_clr_128_wde4/archive_model_epoch50_acc0.9963.pt' #incerase weigthday worse\n",
    "# './results/mnist/Apr28_1550_adamw_clr_128/archive_model_epoch50_acc0.9988.pt'\n",
    "# './results/mnist/Apr28_1626_rmsprop_clr_128/archive_model_epoch50_acc0.9936.pt'\n",
    "# './results/mnist/Apr28_1641_adam_exp_128/archive_model_epoch50_acc0.9979.pt'\n",
    "# './results/mnist/Apr28_1719_adam_exp_128_lre3/archive_model_epoch50_acc0.9982.pt'\n",
    "# './results/mnist/Apr28_1745_adam_exp_128_lre3_lamrecon5/archive_model_epoch50_acc0.9986.pt'\n",
    "# './results/mnist/Apr28_1815_capsnetencoder_cycle/archive_model_epoch220_acc0.9961.pt'\n",
    "\n",
    "# './results/mnist/Apr28_2001_shift_adamclr/archive_model_epoch50_acc0.9860.pt'\n",
    "\n",
    "# Clean-CLR\n",
    "# './results/mnist/Apr29_0212_clean_clr_run1/best_epoch174_acc0.9993.pt',\n",
    "# './results/mnist/Apr29_0321_clean_clr_run2/best_epoch163_acc0.9993.pt',\n",
    "# './results/mnist/Apr29_0427_clean_clr_run3/best_epoch186_acc0.9994.pt',\n",
    "# './results/mnist/Apr29_0540_clean_clr_run4/best_epoch212_acc0.9995.pt',\n",
    "# './results/mnist/Apr29_0703_clean_clr_run5/earlystop_245_acc0.9995.pt',\n",
    "\n",
    "    \n",
    "# Clean-WD 0.0005, 0.98\n",
    "# './results/mnist/Apr29_1353_clean_wd2_run1/best_epoch85_acc0.9983.pt',\n",
    "# './results/mnist/Apr29_1435_clean_wd2_run2/best_epoch95_acc0.9986.pt',\n",
    "# './results/mnist/Apr29_1704_clean_wd2_run3/best_epoch105_acc0.9988.pt',\n",
    "# './results/mnist/Apr29_1749_clean_wd2_run4/best_epoch92_acc0.9983.pt',\n",
    "# './results/mnist/Apr29_1829_clean_wd2_run5/best_epoch115_acc0.9987.pt',\n",
    "    \n",
    "\n",
    "    \n",
    "# Shift-WD\n",
    "# './results/mnist/Apr30_0304_shift_run1/best_epoch103_acc0.9966.pt',\n",
    "# './results/mnist/Apr30_0400_shift_run2/best_epoch78_acc0.9977.pt',\n",
    "# './results/mnist/Apr30_0425_shift_run3/best_epoch85_acc0.9973.pt',\n",
    "# './results/mnist/Apr30_0450_shift_run4/best_epoch80_acc0.9958.pt',\n",
    "# './results/mnist/Apr30_0513_shift_run5/best_epoch64_acc0.9978.pt'\n",
    "\n",
    "    \n",
    "# Clean-Aug-WD\n",
    "# './results/mnist/May25_0235_clean_aug_run1/best_epoch84_acc0.9662.pt',\n",
    "# './results/mnist/May25_0323_clean_aug_run2/best_epoch83_acc0.9714.pt',\n",
    "# './results/mnist/May25_0411_clean_aug_run3/best_epoch99_acc0.9713.pt',\n",
    "# './results/mnist/May25_0506_clean_aug_run4/best_epoch81_acc0.9664.pt',\n",
    "# './results/mnist/May25_0554_clean_aug_run5/best_epoch75_acc0.9713.pt'\n",
    "\n",
    "    \n",
    "    \n",
    "# Clean-WD\n",
    "# './results/mnist/Apr29_0213_clean_wd_run1/best_epoch75_acc0.9981.pt',\n",
    "# './results/mnist/Apr29_0247_clean_wd_run2/best_epoch81_acc0.9987.pt',\n",
    "# './results/mnist/Apr29_0322_clean_wd_run3/best_epoch88_acc0.9987.pt',\n",
    "# './results/mnist/Apr29_0400_clean_wd_run4/best_epoch62_acc0.9980.pt',\n",
    "# './results/mnist/Apr29_0429_clean_wd_run5/best_epoch71_acc0.9987.pt',\n",
    "    \n",
    "# Recon-blur-WD\n",
    "# './results/mnist/Apr30_0144_recon_run1/best_epoch81_acc0.9983.pt',\n",
    "# './results/mnist/Apr30_0208_recon_run2/best_epoch73_acc0.9986.pt',\n",
    "# './results/mnist/Apr30_0230_recon_run3/best_epoch77_acc0.9986.pt',\n",
    "# './results/mnist/Apr30_0253_recon_run4/best_epoch63_acc0.9981.pt',\n",
    "# './results/mnist/Apr30_0321_recon_run5/best_epoch77_acc0.9987.pt',\n",
    "    \n",
    "# resnet-blur version\n",
    "# './results/mnist/May29_0416_blur_res_run1/best_epoch21_acc1.0000.pt',\n",
    "# './results/mnist/May29_0427_blur_res_run2/best_epoch30_acc1.0000.pt',\n",
    "# './results/mnist/May29_0440_blur_res_run3/best_epoch37_acc1.0000.pt',\n",
    "# './results/mnist/May29_0455_blur_res_run4/best_epoch36_acc1.0000.pt',\n",
    "# './results/mnist/May29_0510_blur_res_run5/best_epoch29_acc1.0000.pt'\n",
    "\n",
    "# resnet 4 layers -blur\n",
    "# './results/mnist/May29_2045_blur_res4_run1/best_epoch32_acc1.0000.pt',\n",
    "# './results/mnist/May29_2056_blur_res4_run2/best_epoch32_acc1.0000.pt',\n",
    "# './results/mnist/May29_2109_blur_res4_run3/best_epoch32_acc1.0000.pt',\n",
    "# './results/mnist/May29_2121_blur_res4_run4/best_epoch30_acc1.0000.pt',\n",
    "# './results/mnist/May29_2132_blur_res4_run5/best_epoch30_acc1.0000.pt'\n",
    "\n",
    "# resnet 4 layers - lsf\n",
    "# './results/mnist/Aug14_0508_lsf_res4_run1/best_epoch30_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0524_lsf_res4_run2/best_epoch29_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0540_lsf_res4_run3/best_epoch26_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0556_lsf_res4_run4/best_epoch29_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0612_lsf_res4_run5/best_epoch28_acc1.0000.pt'\n",
    "\n",
    "# resnet 4 layers - hsf\n",
    "# './results/mnist/Aug14_0508_hsf_res4_run1/best_epoch32_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0525_hsf_res4_run2/best_epoch25_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0540_hsf_res4_run3/best_epoch27_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0556_hsf_res4_run4/best_epoch30_acc1.0000.pt',\n",
    "# './results/mnist/Aug14_0612_hsf_res4_run5/best_epoch28_acc1.0000.pt'\n",
    "    \n",
    "# cnn 2 layers - lsf\n",
    "'./results/mnist/Aug14_0805_lsf_conv_run5/best_epoch88_acc0.9988.pt',\n",
    "'./results/mnist/Aug14_0740_lsf_conv_run4/best_epoch86_acc0.9982.pt',\n",
    "'./results/mnist/Aug14_0721_lsf_conv_run3/best_epoch60_acc0.9987.pt',\n",
    "'./results/mnist/Aug14_0658_lsf_conv_run2/best_epoch78_acc0.9987.pt',\n",
    "'./results/mnist/Aug14_0635_lsf_conv_run1/best_epoch74_acc0.9981.pt'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['corruption'] = CORRUPTION_TYPES\n",
    "\n",
    "for load_model_path in modelpathlist:    \n",
    "#     modelname = '-'.join( os.path.dirname(load_model_path).split('_')[-3:-1]) #'recon-step3'\n",
    "    modelname = load_model_path.split('/')[-1] # filename\n",
    "    print(f'test starts on {modelname}')\n",
    "    \n",
    "    # load args and model  \n",
    "    args = load_args(load_model_path, args_to_update, print_args)\n",
    "    model = load_model(args)\n",
    "    \n",
    "    acclist = []\n",
    "    for corruption in CORRUPTION_TYPES:\n",
    "        test_loss, test_loss_class, test_loss_recon, test_acc = test_model_on_each_corruption(PATH_MNISTC, corruption, model, verbose)\n",
    "        acclist.append(test_acc*100)\n",
    "    df[load_model_path] = acclist\n",
    "\n",
    "\n",
    "df.index = np.arange(1, len(df)+1)\n",
    "df.loc['AVERAGE'] = df.mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d794ac5b-0963-4e66-99eb-f57876b5cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done! df is saved to csv as model-results-rrcapsnet-lowpass-conv-G1L1.csv\n"
     ]
    }
   ],
   "source": [
    "# save to csv\n",
    "# path_df = 'model-results-rrcapsnet-clean-G4L3.csv'\n",
    "# path_df = 'model-results-rrcapsnet-shift-G4L3.csv'\n",
    "# path_df = 'model-results-rrcapsnet-recon-G1L1.csv'\n",
    "path_df = 'model-results-rrcapsnet-clean-aug-G4L3.csv'\n",
    "path_df = 'model-results-rrcapsnet-blur-resnet4-G1L1.csv'\n",
    "path_df = 'model-results-rrcapsnet-lowpass-resnet4-G4L1.csv'\n",
    "path_df = 'model-results-rrcapsnet-highpass-resnet4-G1L1.csv'\n",
    "path_df = 'model-results-rrcapsnet-lowpass-conv-G1L1.csv'\n",
    "\n",
    "overwrite = True\n",
    "if os.path.isfile(path_df) and not overwrite:\n",
    "    print(f'test done! file {path_df} already exists, df is not saved')\n",
    "else: \n",
    "    df.to_csv(path_df, index=False)\n",
    "    print(f'test done! df is saved to csv as {path_df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb00a4-11f7-4f0e-a252-606c1de1d3e7",
   "metadata": {},
   "source": [
    "# On shape purturbed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e203fa0-7cac-48b3-91a4-30c020bb2932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test starts on best_epoch81_acc0.9983.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n",
      "original mnist dataset\n",
      "test starts on best_epoch73_acc0.9986.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n",
      "original mnist dataset\n",
      "test starts on best_epoch77_acc0.9986.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n",
      "original mnist dataset\n",
      "test starts on best_epoch63_acc0.9981.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n",
      "original mnist dataset\n",
      "test starts on best_epoch77_acc0.9987.pt\n",
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 1\n",
      "ENCODER: two-conv-layer w/ None projection\n",
      "...resulting primary caps #: 1152, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "========================================================\n",
      "\n",
      "original mnist dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>./results/mnist/Apr30_0144_recon_run1/best_epoch81_acc0.9983.pt</th>\n",
       "      <th>./results/mnist/Apr30_0208_recon_run2/best_epoch73_acc0.9986.pt</th>\n",
       "      <th>./results/mnist/Apr30_0230_recon_run3/best_epoch77_acc0.9986.pt</th>\n",
       "      <th>./results/mnist/Apr30_0253_recon_run4/best_epoch63_acc0.9981.pt</th>\n",
       "      <th>./results/mnist/Apr30_0321_recon_run5/best_epoch77_acc0.9987.pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mnist</td>\n",
       "      <td>99.030004</td>\n",
       "      <td>99.150004</td>\n",
       "      <td>99.060004</td>\n",
       "      <td>99.150005</td>\n",
       "      <td>99.110004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnist_occlusion</td>\n",
       "      <td>91.280004</td>\n",
       "      <td>91.820006</td>\n",
       "      <td>91.260004</td>\n",
       "      <td>90.870005</td>\n",
       "      <td>91.760005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnist_flipped</td>\n",
       "      <td>70.540003</td>\n",
       "      <td>70.250003</td>\n",
       "      <td>69.910004</td>\n",
       "      <td>70.620003</td>\n",
       "      <td>71.050004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnist_random</td>\n",
       "      <td>36.190002</td>\n",
       "      <td>36.950002</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>36.960001</td>\n",
       "      <td>36.730002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              task  \\\n",
       "0            mnist   \n",
       "1  mnist_occlusion   \n",
       "2    mnist_flipped   \n",
       "3     mnist_random   \n",
       "\n",
       "   ./results/mnist/Apr30_0144_recon_run1/best_epoch81_acc0.9983.pt  \\\n",
       "0                                          99.030004                 \n",
       "1                                          91.280004                 \n",
       "2                                          70.540003                 \n",
       "3                                          36.190002                 \n",
       "\n",
       "   ./results/mnist/Apr30_0208_recon_run2/best_epoch73_acc0.9986.pt  \\\n",
       "0                                          99.150004                 \n",
       "1                                          91.820006                 \n",
       "2                                          70.250003                 \n",
       "3                                          36.950002                 \n",
       "\n",
       "   ./results/mnist/Apr30_0230_recon_run3/best_epoch77_acc0.9986.pt  \\\n",
       "0                                          99.060004                 \n",
       "1                                          91.260004                 \n",
       "2                                          69.910004                 \n",
       "3                                          35.900002                 \n",
       "\n",
       "   ./results/mnist/Apr30_0253_recon_run4/best_epoch63_acc0.9981.pt  \\\n",
       "0                                          99.150005                 \n",
       "1                                          90.870005                 \n",
       "2                                          70.620003                 \n",
       "3                                          36.960001                 \n",
       "\n",
       "   ./results/mnist/Apr30_0321_recon_run5/best_epoch77_acc0.9987.pt  \n",
       "0                                          99.110004                \n",
       "1                                          91.760005                \n",
       "2                                          71.050004                \n",
       "3                                          36.730002                "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################\n",
    "# best model comparison on entire corruptions\n",
    "########################################################\n",
    "tasklist = ['mnist', 'mnist_occlusion', 'mnist_flipped', 'mnist_random']\n",
    "verbose=False\n",
    "print_args =False\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 1, 'routings': 3, 'mask_threshold': 0.1}\n",
    "\n",
    "\n",
    "modelpathlist = [\n",
    "# './models/rrcapsnet/run1_epoch50_acc0.9917.pt',\n",
    "# './models/rrcapsnet/run2_epoch50_acc0.9915.pt',\n",
    "# './models/rrcapsnet/run3_epoch50_acc0.9907.pt',\n",
    "# './models/rrcapsnet/run4_epoch50_acc0.9905.pt',\n",
    "# './models/rrcapsnet/run5_epoch50_acc0.9907.pt',\n",
    "\n",
    "# './results/mnist/Apr28_1352_adam_clr_128/archive_model_epoch50_acc0.9987.pt'\n",
    "# './results/mnist/Apr28_1408_adam_clr_512/archive_model_epoch50_acc0.9953.pt' # increase bn worse\n",
    "# './results/mnist/Apr28_1438_adam_clr_128_wde5/archive_model_epoch50_acc0.9986.pt'\n",
    "# './results/mnist/Apr28_1458_adam_clr_128_wde4/archive_model_epoch50_acc0.9963.pt' #incerase weigthday worse\n",
    "# './results/mnist/Apr28_1550_adamw_clr_128/archive_model_epoch50_acc0.9988.pt'\n",
    "# './results/mnist/Apr28_1626_rmsprop_clr_128/archive_model_epoch50_acc0.9936.pt'\n",
    "# './results/mnist/Apr28_1641_adam_exp_128/archive_model_epoch50_acc0.9979.pt'\n",
    "# './results/mnist/Apr28_1719_adam_exp_128_lre3/archive_model_epoch50_acc0.9982.pt'\n",
    "# './results/mnist/Apr28_1745_adam_exp_128_lre3_lamrecon5/archive_model_epoch50_acc0.9986.pt'\n",
    "# './results/mnist/Apr28_1815_capsnetencoder_cycle/archive_model_epoch220_acc0.9961.pt'\n",
    "\n",
    "# './results/mnist/Apr28_2001_shift_adamclr/archive_model_epoch50_acc0.9860.pt'\n",
    "\n",
    "# Clean-CLR\n",
    "# './results/mnist/Apr29_0212_clean_clr_run1/best_epoch174_acc0.9993.pt',\n",
    "# './results/mnist/Apr29_0321_clean_clr_run2/best_epoch163_acc0.9993.pt',\n",
    "# './results/mnist/Apr29_0427_clean_clr_run3/best_epoch186_acc0.9994.pt',\n",
    "# './results/mnist/Apr29_0540_clean_clr_run4/best_epoch212_acc0.9995.pt',\n",
    "# './results/mnist/Apr29_0703_clean_clr_run5/earlystop_245_acc0.9995.pt',\n",
    "    \n",
    "# Clean-WD\n",
    "# './results/mnist/Apr29_0213_clean_wd_run1/best_epoch75_acc0.9981.pt',\n",
    "# './results/mnist/Apr29_0247_clean_wd_run2/best_epoch81_acc0.9987.pt',\n",
    "# './results/mnist/Apr29_0322_clean_wd_run3/best_epoch88_acc0.9987.pt',\n",
    "# './results/mnist/Apr29_0400_clean_wd_run4/best_epoch62_acc0.9980.pt',\n",
    "# './results/mnist/Apr29_0429_clean_wd_run5/best_epoch71_acc0.9987.pt',\n",
    "    \n",
    "# Clean-WD 0.0005, 0.98\n",
    "# './results/mnist/Apr29_1353_clean_wd2_run1/best_epoch85_acc0.9983.pt',\n",
    "# './results/mnist/Apr29_1435_clean_wd2_run2/best_epoch95_acc0.9986.pt',\n",
    "# './results/mnist/Apr29_1704_clean_wd2_run3/best_epoch105_acc0.9988.pt',\n",
    "# './results/mnist/Apr29_1749_clean_wd2_run4/best_epoch92_acc0.9983.pt',\n",
    "# './results/mnist/Apr29_1829_clean_wd2_run5/best_epoch115_acc0.9987.pt',\n",
    "    \n",
    "# Recon-WD\n",
    "# './results/mnist/Apr30_0144_recon_run1/best_epoch81_acc0.9983.pt',\n",
    "# './results/mnist/Apr30_0208_recon_run2/best_epoch73_acc0.9986.pt',\n",
    "# './results/mnist/Apr30_0230_recon_run3/best_epoch77_acc0.9986.pt',\n",
    "# './results/mnist/Apr30_0253_recon_run4/best_epoch63_acc0.9981.pt',\n",
    "# './results/mnist/Apr30_0321_recon_run5/best_epoch77_acc0.9987.pt',\n",
    "    \n",
    "# Shift-WD\n",
    "# './results/mnist/Apr30_0304_shift_run1/best_epoch103_acc0.9966.pt',\n",
    "# './results/mnist/Apr30_0400_shift_run2/best_epoch78_acc0.9977.pt',\n",
    "# './results/mnist/Apr30_0425_shift_run3/best_epoch85_acc0.9973.pt',\n",
    "# './results/mnist/Apr30_0450_shift_run4/best_epoch80_acc0.9958.pt',\n",
    "# './results/mnist/Apr30_0513_shift_run5/best_epoch64_acc0.9978.pt'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['task'] = tasklist\n",
    "\n",
    "for load_model_path in modelpathlist:    \n",
    "#     modelname = '-'.join( os.path.dirname(load_model_path).split('_')[-3:-1]) #'recon-step3'\n",
    "    modelname = load_model_path.split('/')[-1] # filename\n",
    "    print(f'test starts on {modelname}')\n",
    "    \n",
    "    # load args and model  \n",
    "    args = load_args(load_model_path, args_to_update, print_args)\n",
    "    model = load_model(args)\n",
    "    \n",
    "    acclist=[]\n",
    "    for task in tasklist:\n",
    "        _, _, _,acc = test_model(task, model, args)\n",
    "        acclist.append(acc*100)\n",
    "        \n",
    "    df[load_model_path] = acclist\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03752131-50af-49c0-a15d-9f118b0b109d",
   "metadata": {},
   "source": [
    "# for comparing models under the same experiment folder\n",
    "obtain best model from each experiment and compare overall accuracy\n",
    "- all pretrained models to be compared should be saved under the same folder \n",
    "- output is df file and will be saved to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d468ea4-d875-47d0-8d31-6ce9aa053d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# set up info for model testing\n",
    "##################\n",
    "task='mnist_recon' #train on mnist_recon, test on mnistc_mini\n",
    "task='mnist_c' #test on 15 benchmark corruption + 1 identity \n",
    "\n",
    "# get best model files under experiment path\n",
    "path_experiment = './results/mnist/experiment-recon-norecon'\n",
    "bestfiles, expnames = get_bestmodel_paths(path_experiment)\n",
    "expname_format = ['use_recon','n_step', 'seed'] # what's writte n after timestamp\n",
    "# expname_format = ['use_recon','n_step', 'inputmatch', 'seed']\n",
    "\n",
    "# arguments to update\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 4, 'routings': 3, 'routing_type': 'pd-recon', #'original' \n",
    "                 'min_coup': 0.5, 'min_rscore': 0.5, 'mask_threshold': 0.1}\n",
    "print_args =False\n",
    "\n",
    "\n",
    "##################\n",
    "# main - model testing\n",
    "##################\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame()\n",
    "df['model_path'] = bestfiles\n",
    "df['exp_name'] = expnames\n",
    "df[expname_format] = df['exp_name'].str.split('_',expand=True)\n",
    "df['exp_name'] = df['exp_name'].str.split('_').str[:-1].str.join('_') #expname without seed\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(f'test begin on {i+1}th model')\n",
    "\n",
    "    # load model\n",
    "    load_model_path = row['model_path']   \n",
    "    args = load_args(load_model_path, args_to_update, print_args)\n",
    "    model = load_model(args)\n",
    "\n",
    "    # test model\n",
    "    if task == 'mnist_c':\n",
    "        df.loc[i,'test_loss'], df.loc[i,'test_loss_class'], df.loc[i,'test_loss_recon'], df.loc[i,'test_acc'] = test_model_mnistc(PATH_MNISTC, CORRUPTION_TYPES, model)\n",
    "    else:\n",
    "        df.loc[i,'test_loss'], df.loc[i,'test_loss_class'], df.loc[i,'test_loss_recon'], df.loc[i,'test_acc'] = test_model(task, model, args)\n",
    "    #     test_loss, test_loss_class, test_loss_recon, test_acc = test_model(model,args)\n",
    "    \n",
    "print('========== tests are done =============')\n",
    "\n",
    "# save df\n",
    "path_savefile = task + '-'+ os.path.basename(path_experiment) + '.csv'\n",
    "if os.path.isfile(path_savefile):\n",
    "    print(f'csv file already exists: {path_savefile}')\n",
    "else: \n",
    "    df.to_csv(path_savefile)\n",
    "    print(f'csv file saved: {path_savefile}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
