{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce89847a-5da6-4757-ae72-9905206945cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "from visualization import *\n",
    "from rrcapsnet_original import *\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "\n",
    "PATH_MNISTC = '../data/MNIST_C/'\n",
    "CORRUPTION_TYPES = ['identity', \n",
    "         'shot_noise', 'impulse_noise','glass_blur','motion_blur',\n",
    "         'shear', 'scale',  'rotate',  'brightness',  'translate',\n",
    "         'stripe', 'fog','spatter','dotted_line', 'zigzag',\n",
    "         'canny_edges']\n",
    "\n",
    "N_MINI_PER_CORRUPTION = 1000\n",
    "\n",
    "ACC_TYPE = \"entropy\"\n",
    "\n",
    "# general helper funtions for model testing\n",
    "def load_model(args):\n",
    "    # load model\n",
    "    model = RRCapsNet(args).to(args.device) \n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "    return model\n",
    "\n",
    "def load_args(load_model_path, args_to_update, verbose=False):\n",
    "    params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    args = parse_params_wremove(params_filename, removelist = ['device']) \n",
    "    args = update_args(args, args_to_update)\n",
    "    args.load_model_path = load_model_path\n",
    "    if verbose:\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "    return args\n",
    "\n",
    "\n",
    "###########################\n",
    "# evaluate on mnist-c original version\n",
    "############################\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False,  max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    if save_hooks:\n",
    "        def get_attention_outputs():\n",
    "            def hook(model, input, output):\n",
    "                x_mask_step.append(output[0].detach())\n",
    "                x_input_step.append(output[1].detach())\n",
    "            return hook\n",
    "\n",
    "        def get_capsule_outputs():\n",
    "            def hook(model, input, output):\n",
    "                objcaps_step.append(output[0].detach())\n",
    "                coups_step.append(torch.stack(output[1]['coups'], dim=1))\n",
    "                betas_step.append(torch.stack(output[1]['betas'], dim=1)) \n",
    "                if 'rscores' in output[1].keys():\n",
    "                    rscores_step.append(torch.stack(output[1]['rscores'], dim=1))\n",
    "                if 'recon_coups' in output[1].keys():\n",
    "                    recon_coups_step.append(torch.stack(output[1]['recon_coups'], dim=1))\n",
    "                if 'outcaps_len' in output[1].keys():\n",
    "                    outcaps_len_step.append(torch.stack(output[1]['outcaps_len'], dim=1))\n",
    "                if 'outcaps_len_before' in output[1].keys():\n",
    "                    outcaps_len_before_step.append(torch.stack(output[1]['outcaps_len_before'], dim=1))\n",
    "            return hook\n",
    "        \n",
    "        outputs = {}\n",
    "\n",
    "        x_input_step_all = []; x_mask_step_all = []; objcaps_step_all = []\n",
    "\n",
    "        coups_step_all = []; betas_step_all= []; rscores_step_all=[]; recon_coups_step_all=[] \n",
    "        outcaps_len_step_all=[]; outcaps_len_before_step_all=[]\n",
    "\n",
    "    x_all, y_all, gtx_all, loss_all, acc_all, objcaps_len_step_all, x_recon_step_all = [],[],[],[],[],[],[]\n",
    "    \n",
    "    model.eval()      \n",
    "    \n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "                \n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "\n",
    "        # for hooks over other model output\n",
    "        x_input_step = []; x_mask_step = []; objcaps_step = []\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # for hooks over dynamic routing\n",
    "            coups_step = []; betas_step= []; rscores_step=[]; recon_coups_step=[] \n",
    "            outcaps_len_step=[]; outcaps_len_before_step=[]\n",
    "\n",
    "            hook1 = model.input_window.register_forward_hook(get_attention_outputs())\n",
    "            hook2 = model.capsule_routing.register_forward_hook(get_capsule_outputs())\n",
    "\n",
    "        # evaluate and append results \n",
    "        losses, acc, objcaps_len_step, x_recon_step = evaluate(model, x, y, args, acc_type=ACC_TYPE, gtx=gtx)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"==> On this sigle test batch: test_loss=%.5f, test_loss_class=%.5f, test_loss_recon=%.5f, test_acc=%.4f\"\n",
    "                  % (losses[0], losses[1], losses[2], acc))   \n",
    "\n",
    "        # main input and output append\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        if gtx:\n",
    "            gtx_all.append(gtx)\n",
    "        #         loss_all.append(losses[0])\n",
    "        acc_all.append(acc)\n",
    "        objcaps_len_step_all.append(objcaps_len_step)\n",
    "        x_recon_step_all.append(x_recon_step)\n",
    "\n",
    "        if save_hooks:\n",
    "\n",
    "            # hook variables append\n",
    "            x_input_step_all.append(torch.stack(x_input_step, dim=1))\n",
    "            x_mask_step_all.append(torch.stack(x_mask_step, dim=1))\n",
    "            objcaps_step_all.append(torch.stack(objcaps_step, dim=1))\n",
    "\n",
    "            coups_step_all.append(torch.stack(coups_step, dim=1))\n",
    "            betas_step_all.append(torch.stack(betas_step, dim=1))\n",
    "            if rscores_step:\n",
    "                rscores_step_all.append(torch.stack(rscores_step, dim=1))\n",
    "            if recon_coups_step:\n",
    "                recon_coups_step_all.append(torch.stack(recon_coups_step, dim=1))\n",
    "            if outcaps_len_step:\n",
    "                outcaps_len_step_all.append(torch.stack(outcaps_len_step, dim=1))\n",
    "            if outcaps_len_before_step:\n",
    "                outcaps_len_before_step_all.append(torch.stack(outcaps_len_before_step, dim=1))\n",
    "\n",
    "            hook1.remove()\n",
    "            hook2.remove()        \n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    if gtx:\n",
    "        gtx_all = torch.cat(gtx_all, dim=0)\n",
    "    else:\n",
    "        gtx_all = gtx\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    objcaps_len_step_all = torch.cat(objcaps_len_step_all, dim=0)\n",
    "    x_recon_step_all = torch.cat(x_recon_step_all, dim=0)\n",
    "    \n",
    "    if save_hooks:\n",
    "        outputs['x_input']= torch.cat(x_input_step_all, dim=0)\n",
    "        outputs['x_mask']= torch.cat(x_mask_step_all, dim=0)\n",
    "        outputs['objcaps']= torch.cat(objcaps_step_all, dim=0)\n",
    "\n",
    "        outputs['coups'] = torch.cat(coups_step_all, dim=0)\n",
    "        outputs['betas'] = torch.cat(betas_step_all, dim=0)\n",
    "        if rscores_step_all:\n",
    "            outputs['rscores'] = torch.cat(rscores_step_all, dim=0)\n",
    "        if recon_coups_step_all:\n",
    "            outputs['recon_coups'] = torch.cat(recon_coups_step_all, dim=0)\n",
    "        if outcaps_len_step_all:\n",
    "            outputs['outcaps_len'] = torch.cat(outcaps_len_step_all, dim=0)\n",
    "        if outcaps_len_before_step_all:\n",
    "            outputs['outcaps_len_before'] = torch.cat(outcaps_len_before_step_all, dim=0)\n",
    "            \n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all, outputs  \n",
    "\n",
    "    else:\n",
    "        return x_all, gtx_all, y_all, acc_all, objcaps_len_step_all, x_recon_step_all\n",
    "    \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_cnn_on_mnistc_original(corruption, cnn, max_batch_num=None):\n",
    "    path_images = os.path.join(PATH_MNISTC, corruption, 'test_images.npy')\n",
    "    path_labels = os.path.join(PATH_MNISTC, corruption, 'test_labels.npy')\n",
    "\n",
    "    # convert to torch\n",
    "    images = np.load(path_images)\n",
    "    labels = np.load(path_labels)\n",
    "    transform_tohot = T.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "    images_tensorized = torch.stack([T.ToTensor()(im) for im in images])\n",
    "    labels_tensorized = torch.stack([transform_tohot(label) for label in labels])\n",
    "    # print(images_tensorized.shape) #torch.Size([10000, 1, 28, 28])\n",
    "    # print(labels_tensorized.shape) #torch.Size([10000, 10])\n",
    "\n",
    "    # create dataloader\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if DEVICE == 'cuda' else {}\n",
    "    dataset = TensorDataset(images_tensorized, labels_tensorized)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    # save output\n",
    "    x_all, y_all, pred_all, acc_all, class_prob_all = [],[],[], [],[]\n",
    "    cnn.eval() \n",
    "\n",
    "    # get input and gt\n",
    "    i=0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        gtx = None\n",
    "        \n",
    "        if max_batch_num:\n",
    "            if i == max_batch_num:\n",
    "                break\n",
    "\n",
    "#         if i == max_batch_num:\n",
    "#             x, y = data\n",
    "#             gtx = None\n",
    "                    \n",
    "        data, target = x.to(DEVICE),  y.to(DEVICE)\n",
    "        target = target.argmax(dim=1, keepdim=True)\n",
    "        output = cnn(data)\n",
    "        #                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        acc = pred.eq(target.view_as(pred))\n",
    "\n",
    "        x_all.append(data)\n",
    "        y_all.append(target.flatten())\n",
    "        pred_all.append(pred.flatten())\n",
    "        acc_all.append(acc.flatten().float())\n",
    "        class_prob_all.append(output)\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "\n",
    "    # concat and add to outputs dictionary\n",
    "    x_all = torch.cat(x_all, dim=0)\n",
    "    y_all = torch.cat(y_all, dim=0)\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    acc_all = torch.cat(acc_all, dim=0)\n",
    "    class_prob_all = torch.cat(class_prob_all, dim=0)\n",
    "\n",
    "    return x_all, y_all, class_prob_all, pred_all, acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50e977f-63b6-4307-a19c-01982d74457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "\n",
    "def save_imgarr(imgarr, filename='test.png', scale=8):\n",
    "    h, w, _ = imgarr.shape\n",
    "    fig, axes = plt.subplots(figsize=(h*scale, w*scale))\n",
    "    fig.subplots_adjust(top=1.0, bottom=0, right=1.0, left=0, hspace=0, wspace=0) \n",
    "    axes.imshow(imgarr, cmap='gray_r')\n",
    "    axes.axis('off')\n",
    "    plt.savefig(filename, dpi=1, format='png') \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad7bb6",
   "metadata": {},
   "source": [
    "# experiment 2: analyze errors and compare with cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924cf182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== model instantiated like below: =============\n",
      "TASK: mnist_recon_low (# targets: 1, # classes: 10, # background: 0)\n",
      "TIMESTEPS #: 5\n",
      "ENCODER: resnet w/ None projection\n",
      "...resulting primary caps #: 288, dim: 8\n",
      "ROUTINGS # 3\n",
      "Object #: 10, BG Capsule #: 0\n",
      "DECODER: fcn, w/ None projection\n",
      "...recon only one object capsule: True\n",
      "...use recon mask for attention: True\n",
      "...with mask type bool, threshold 0.1, apply_method match\n",
      "========================================================\n",
      "\n",
      "original is used\n",
      "==> corruption type: motion_blur, this batch acc: 0.9667999744415283\n",
      "original is used\n",
      "==> corruption type: motion_blur, this batch acc: 0.9440999627113342\n",
      "55\n",
      "trialinfo saved to disk!\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# test a single model, and visualize outputs\n",
    "#############################\n",
    "task='mnist_c_original'\n",
    "\n",
    "train=False #train or test dataset\n",
    "print_args=False\n",
    "\n",
    "\n",
    "# load our model\n",
    "args_to_update = {'device':DEVICE, 'batch_size':BATCHSIZE, \n",
    "                 'time_steps': 5, 'routings': 3,'mask_threshold': 0.1}\n",
    "\n",
    "load_model_path = './models/rrcapsnet/rrcapsnet_best.pt'\n",
    "# load_model_path = './results/mnist/Aug14_0508_lsf_res4_run1/best_epoch30_acc1.0000.pt'\n",
    "\n",
    "args = load_args(load_model_path, args_to_update, print_args)\n",
    "model = load_model(args)\n",
    "\n",
    "# load cnn\n",
    "from train_cnn import *\n",
    "path_cnn = './models/cnn/cnn_best.pt'\n",
    "cnn = Net().to(DEVICE)\n",
    "cnn.load_state_dict(torch.load(path_cnn))\n",
    "cnn.eval()\n",
    "\n",
    "path_save = './stimuli/stimuli-exp2-step5/'\n",
    "\n",
    "\n",
    "\n",
    "# obtain model predictions\n",
    "# CORRUPTION_INTEREST = ['identity', 'glass_blur','motion_blur', 'impulse_noise','shot_noise',\n",
    "#         'fog','dotted_line','spatter', 'zigzag']\n",
    "CORRUPTION_INTEREST = ['motion_blur']\n",
    "\n",
    "for corruption in CORRUPTION_INTEREST :\n",
    "\n",
    "    if task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        x, gtx, y_hot, acc_model, objcaps_len_step, x_recon_step = \\\n",
    "        evaluate_model_on_mnistc_original(corruption, model, verbose=False, save_hooks=False)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_model.mean().item()}')\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # get model prediction\n",
    "    objcaps_len_step_narrow = objcaps_len_step.narrow(dim=2,start=0, length=args.num_classes)\n",
    "    # pred_model = objcaps_len_step_narrow.max(dim=-1)[1][:,-1] #torch.Size([1000, 3])\n",
    "\n",
    "\n",
    "    if ACC_TYPE=='hypothesis':\n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else:\n",
    "            acc_model_check, pred_model, nstep  = compute_hypothesis_based_acc(objcaps_len_step_narrow, y_hot, only_acc=False)\n",
    "\n",
    "    elif ACC_TYPE == 'entropy':    \n",
    "        if args.time_steps==1:\n",
    "            y_pred = objcaps_len_step_narrow[:,-1]\n",
    "            accs = topkacc(y_pred, y_true, topk=1)\n",
    "        else: \n",
    "            acc_model_check, pred_model, nstep, no_stop_condition, entropy_model =compute_entropy_based_acc(objcaps_len_step_narrow, y_hot, threshold=0.6, use_cumulative = False, only_acc= False)\n",
    "\n",
    "    assert round(acc_model.mean().item(), 4) == round(acc_model_check.float().mean().item(), 4)\n",
    "\n",
    "\n",
    "    ##################\n",
    "    # get cnn prediction\n",
    "    ##################\n",
    "    if task =='mnist_c_original':\n",
    "        print(\"original is used\")\n",
    "        data_cnn, target_cnn, logsoft_cnn, pred_cnn, acc_cnn \\\n",
    "        =  evaluate_cnn_on_mnistc_original(corruption, cnn)\n",
    "        print(f'==> corruption type: {corruption}, this batch acc: {acc_cnn.float().mean().item()}')\n",
    "        \n",
    "        \n",
    "    #######################\n",
    "    # get trials id where both model fails & disagree\n",
    "    #######################\n",
    "    assert (target_cnn.cpu() == y_hot.max(dim=1)[1].cpu()).all()\n",
    "    bool_bothincorrect = ~(acc_model.bool())* ~(acc_cnn.bool())\n",
    "    bool_diffanswer = (pred_model!= pred_cnn)\n",
    "    bool_onlycnncorrect = ~(acc_model.bool())* (acc_cnn.bool())\n",
    "    # idx_bothincorrect = torch.nonzero(bool_bothincorrect)\n",
    "    trialid_interest = torch.nonzero(bool_bothincorrect*bool_diffanswer).flatten().tolist()\n",
    "    # trialid_interest = torch.nonzero(bool_onlycnncorrect*bool_diffanswer).flatten().tolist()\n",
    "    print(len(trialid_interest))\n",
    "    \n",
    "    #####################\n",
    "    # save image (in reverted grayscale) and trialinfo\n",
    "    #####################\n",
    "    d = collections.defaultdict(dict)\n",
    "    MAX_TRIAL = 20\n",
    "\n",
    "    trialid_to_visualize = random.sample(trialid_interest, min(len(trialid_interest), MAX_TRIAL))\n",
    "\n",
    "    for trialid in trialid_to_visualize:\n",
    "        cnn_pred = pred_cnn[trialid].cpu().item()\n",
    "        our_pred = pred_model[trialid].cpu().item()\n",
    "        gt =target_cnn[trialid].cpu().item()\n",
    "\n",
    "        # save image x8 original pixel size\n",
    "        imgarray = x[trialid].numpy()\n",
    "        filename = f'{corruption}_t{trialid}_g{gt}_c{cnn_pred}_o{our_pred}.png'\n",
    "        save_imgarr(np.transpose(imgarray,(1,2,0)), filename=path_save+filename)\n",
    "\n",
    "        # save trial info to dictionary\n",
    "        d[filename]['id'] = trialid\n",
    "        d[filename]['imgarray'] = imgarray.tolist()\n",
    "        d[filename]['cnn_softmax'] = torch.exp(logsoft_cnn[trialid]).cpu().numpy().tolist()\n",
    "        d[filename]['our_objlen'] = objcaps_len_step_narrow[trialid, -1].cpu().numpy().tolist()\n",
    "        d[filename]['cnn_pred'] = cnn_pred\n",
    "        d[filename]['our_pred'] = our_pred\n",
    "        d[filename]['gt'] =  gt\n",
    "\n",
    "\n",
    "    # save dictionary\n",
    "    with open(path_save+ f'{corruption}.json', 'w') as fp:\n",
    "        json.dump(d, fp)\n",
    "    print('trialinfo saved to disk!')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e867598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity 5\n",
      "glass_blur 20\n",
      "motion_blur 20\n",
      "impulse_noise 20\n",
      "shot_noise 20\n",
      "fog 20\n",
      "zigzag 20\n"
     ]
    }
   ],
   "source": [
    "# how many trials we have for each corruption\n",
    "# CORRUPTION_INTEREST = ['identity', 'glass_blur','motion_blur', 'impulse_noise','shot_noise',\n",
    "#         'fog','dotted_line','spatter', 'zigzag']\n",
    "\n",
    "CORRUPTION_INTEREST = ['identity', 'glass_blur','motion_blur', 'impulse_noise','shot_noise', 'fog', 'zigzag']\n",
    "\n",
    "for corruption in CORRUPTION_INTEREST :\n",
    "    with open(f'./stimuli/stimuli-exp2-step5/{corruption}.json') as json_file:\n",
    "        jfile = json.load(json_file)\n",
    "        \n",
    "    print(corruption, len(jfile))\n",
    "\n",
    "# the following condition won't be included because not enough trials \n",
    "# dotted_line 12\n",
    "# spatter 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4c001-8f01-45aa-836b-5844215c9806",
   "metadata": {},
   "source": [
    "# Create experiment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55de0b1-d34e-4f52-a785-9d56b2691cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482f1e64-dc3c-49cc-abec-0a93b0b2b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# create prac trials\n",
    "############################\n",
    "# colnames = ['trialtype', 'corruption', 'imgID', 'gt', 'cnn', 'our', 'imgpath', 'maskpath',\n",
    "#            'q1', 'q2', 'q1_text', 'q2_text', 'q1_from', 'q2_from']\n",
    "colnames = ['trialtype', 'corruption', 'imgID', 'gt', 'cnn', 'our', 'imgpath', \n",
    "           'q1', 'q2', 'q1_text', 'q2_text', 'q1_from', 'q2_from']\n",
    "df = pd.DataFrame(columns= colnames )\n",
    "\n",
    "###########\n",
    "# create trial info from filenames\n",
    "###########\n",
    "path_exp = 'stimuli/stimuli-exp2-step5/'\n",
    "# masklist = ['stimuli/stimuli-mask/'+f for f in os.listdir('stimuli/stimuli-mask/') if not f.startswith('.')]\n",
    "# masklist = [f for f in os.listdir('stimuli-mask/') if not f.startswith('.')]\n",
    "\n",
    "i=1\n",
    "for f in os.listdir(path_exp):\n",
    "    if f.endswith('png'):\n",
    "        corruption = '_'.join(f.split('_')[:-4])\n",
    "        if corruption == 'identity': #use as practice trials\n",
    "            trialtype = 'prac'\n",
    "        else:\n",
    "            trialtype = 'exp'        \n",
    "        imgID = int(f.split('_')[-4][1:])\n",
    "        gt = int(f.split('_')[-3][1:])\n",
    "        cnn = int(f.split('_')[-2][1])\n",
    "        our = int(f.split('_')[-1][1])\n",
    "        imgpath = 'stimuli/' + f #path_exp + f\n",
    "#         imgpath = f\n",
    "#         maskpath= random.sample(masklist,1)[0]\n",
    "        \n",
    "        # counterbalance the question rating order\n",
    "        if i%2==0: #even case-> rating1 is cnn's answer and rating 2 is ours\n",
    "            q1 = cnn\n",
    "            q2 = our\n",
    "            q1_text = f'How likely is this digit to be {q1}?'\n",
    "            q2_text =f'How likely is this digit to be {our}?'\n",
    "            q1_from = 'cnn'\n",
    "            q2_from = 'our'\n",
    "        else: # odd case\n",
    "            q1 = our\n",
    "            q2 = cnn\n",
    "            q1_text = f'How likely is this digit to be {our}?'\n",
    "            q2_text =f'How likely is this digit to be {cnn}?'            \n",
    "            q1_from = 'our'\n",
    "            q2_from = 'cnn'            \n",
    "\n",
    "#         df.loc[i] = [trialtype, corruption, imgID, gt, cnn, our, imgpath, maskpath,\n",
    "#                        q1, q2, q1_text, q2_text, q1_from, q2_from]   \n",
    "        df.loc[i] = [trialtype, corruption, imgID, gt, cnn, our, imgpath,\n",
    "                       q1, q2, q1_text, q2_text, q1_from, q2_from]   \n",
    "        i+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b6f01-e00b-4f43-bf31-6455e22534f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialtype</th>\n",
       "      <th>corruption</th>\n",
       "      <th>imgID</th>\n",
       "      <th>gt</th>\n",
       "      <th>cnn</th>\n",
       "      <th>our</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q1_text</th>\n",
       "      <th>q2_text</th>\n",
       "      <th>q1_from</th>\n",
       "      <th>q2_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exp</td>\n",
       "      <td>impulse_noise</td>\n",
       "      <td>2732</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>stimuli/impulse_noise_t2732_g6_c5_o8.png</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>How likely is this digit to be 5?</td>\n",
       "      <td>our</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp</td>\n",
       "      <td>zigzag</td>\n",
       "      <td>4676</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>stimuli/zigzag_t4676_g1_c2_o4.png</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>How likely is this digit to be 2?</td>\n",
       "      <td>How likely is this digit to be 4?</td>\n",
       "      <td>cnn</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exp</td>\n",
       "      <td>shot_noise</td>\n",
       "      <td>6632</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>stimuli/shot_noise_t6632_g9_c5_o8.png</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>How likely is this digit to be 5?</td>\n",
       "      <td>our</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exp</td>\n",
       "      <td>fog</td>\n",
       "      <td>6785</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>stimuli/fog_t6785_g2_c8_o4.png</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>How likely is this digit to be 4?</td>\n",
       "      <td>cnn</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exp</td>\n",
       "      <td>glass_blur</td>\n",
       "      <td>1247</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>stimuli/glass_blur_t1247_g9_c7_o5.png</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>How likely is this digit to be 5?</td>\n",
       "      <td>How likely is this digit to be 7?</td>\n",
       "      <td>our</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>exp</td>\n",
       "      <td>impulse_noise</td>\n",
       "      <td>3926</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>stimuli/impulse_noise_t3926_g9_c8_o3.png</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>How likely is this digit to be 3?</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>our</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>exp</td>\n",
       "      <td>fog</td>\n",
       "      <td>4176</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>stimuli/fog_t4176_g2_c4_o8.png</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>How likely is this digit to be 4?</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>cnn</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>exp</td>\n",
       "      <td>zigzag</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>stimuli/zigzag_t96_g1_c4_o7.png</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>How likely is this digit to be 7?</td>\n",
       "      <td>How likely is this digit to be 4?</td>\n",
       "      <td>our</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>exp</td>\n",
       "      <td>motion_blur</td>\n",
       "      <td>6577</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>stimuli/motion_blur_t6577_g7_c1_o8.png</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>How likely is this digit to be 1?</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>cnn</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>exp</td>\n",
       "      <td>impulse_noise</td>\n",
       "      <td>7856</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>stimuli/impulse_noise_t7856_g1_c2_o8.png</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>How likely is this digit to be 8?</td>\n",
       "      <td>How likely is this digit to be 2?</td>\n",
       "      <td>our</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trialtype     corruption  imgID  gt  cnn  our  \\\n",
       "1         exp  impulse_noise   2732   6    5    8   \n",
       "2         exp         zigzag   4676   1    2    4   \n",
       "3         exp     shot_noise   6632   9    5    8   \n",
       "4         exp            fog   6785   2    8    4   \n",
       "5         exp     glass_blur   1247   9    7    5   \n",
       "..        ...            ...    ...  ..  ...  ...   \n",
       "121       exp  impulse_noise   3926   9    8    3   \n",
       "122       exp            fog   4176   2    4    8   \n",
       "123       exp         zigzag     96   1    4    7   \n",
       "124       exp    motion_blur   6577   7    1    8   \n",
       "125       exp  impulse_noise   7856   1    2    8   \n",
       "\n",
       "                                      imgpath  q1  q2  \\\n",
       "1    stimuli/impulse_noise_t2732_g6_c5_o8.png   8   5   \n",
       "2           stimuli/zigzag_t4676_g1_c2_o4.png   2   4   \n",
       "3       stimuli/shot_noise_t6632_g9_c5_o8.png   8   5   \n",
       "4              stimuli/fog_t6785_g2_c8_o4.png   8   4   \n",
       "5       stimuli/glass_blur_t1247_g9_c7_o5.png   5   7   \n",
       "..                                        ...  ..  ..   \n",
       "121  stimuli/impulse_noise_t3926_g9_c8_o3.png   3   8   \n",
       "122            stimuli/fog_t4176_g2_c4_o8.png   4   8   \n",
       "123           stimuli/zigzag_t96_g1_c4_o7.png   7   4   \n",
       "124    stimuli/motion_blur_t6577_g7_c1_o8.png   1   8   \n",
       "125  stimuli/impulse_noise_t7856_g1_c2_o8.png   8   2   \n",
       "\n",
       "                               q1_text                            q2_text  \\\n",
       "1    How likely is this digit to be 8?  How likely is this digit to be 5?   \n",
       "2    How likely is this digit to be 2?  How likely is this digit to be 4?   \n",
       "3    How likely is this digit to be 8?  How likely is this digit to be 5?   \n",
       "4    How likely is this digit to be 8?  How likely is this digit to be 4?   \n",
       "5    How likely is this digit to be 5?  How likely is this digit to be 7?   \n",
       "..                                 ...                                ...   \n",
       "121  How likely is this digit to be 3?  How likely is this digit to be 8?   \n",
       "122  How likely is this digit to be 4?  How likely is this digit to be 8?   \n",
       "123  How likely is this digit to be 7?  How likely is this digit to be 4?   \n",
       "124  How likely is this digit to be 1?  How likely is this digit to be 8?   \n",
       "125  How likely is this digit to be 8?  How likely is this digit to be 2?   \n",
       "\n",
       "    q1_from q2_from  \n",
       "1       our     cnn  \n",
       "2       cnn     our  \n",
       "3       our     cnn  \n",
       "4       cnn     our  \n",
       "5       our     cnn  \n",
       "..      ...     ...  \n",
       "121     our     cnn  \n",
       "122     cnn     our  \n",
       "123     our     cnn  \n",
       "124     cnn     our  \n",
       "125     our     cnn  \n",
       "\n",
       "[125 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8edc284-64c9-46e9-882f-bed3205ea477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_prac length  5  df_exp length  120\n",
      "['fog' 'glass_blur' 'impulse_noise' 'motion_blur' 'shot_noise' 'zigzag']\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by=['trialtype', 'corruption']).reset_index(drop=True)\n",
    "df_prac = df[df['trialtype']=='prac'].copy()\n",
    "df_exp = df[df['trialtype']=='exp'].copy()\n",
    "\n",
    "print('df_prac length ', len(df_prac), ' df_exp length ', len(df_exp))\n",
    "print(df_exp.corruption.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c8fc2f-54b8-4d52-bda9-bd9ab1062d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source csvs are saved to disk\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# separate into n unique sets; 2sets * 60 images (10*6 corruptions)\n",
    "###############\n",
    "N_SET = 4\n",
    "df_exp['cumcount'] = df_exp.groupby(['corruption']).cumcount()+1\n",
    "df_exp['setnum'] = df_exp['cumcount'].apply(lambda x: int(x%N_SET +1))\n",
    "df_exp = df_exp.drop(columns =['cumcount'])\n",
    "\n",
    "\n",
    "for i in range(1, N_SET+1):\n",
    "    expset = df_exp[df_exp.setnum==i] \n",
    "    expset = expset.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "    combined = df_prac.merge(expset, how='outer') # merge with prac\n",
    "    combined = combined.reset_index(drop=True)\n",
    "    combined['setnum'] = i # since prac parts has no set numbers\n",
    "\n",
    "    combined.to_csv(f'exp2_source{i}.csv', index=False)\n",
    "    \n",
    "print('source csvs are saved to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297269d0-b283-4532-9f98-495d2474e743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "120\n",
      "['zigzag' 'fog' 'glass_blur' 'shot_noise' 'motion_blur' 'impulse_noise']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check; load all expsource and confirm all unique images are covered\n",
    "cats = []\n",
    "for i in range(1, N_SET+1):\n",
    "    test = pd.read_csv(f'exp2_source{i}.csv')\n",
    "    print(len(test)) \n",
    "    test = test[test.trialtype=='exp']\n",
    "    cats.append(test)\n",
    "    \n",
    "c =pd.concat(cats)\n",
    "print(len(c.imgpath.unique()))\n",
    "print(c.corruption.unique())\n",
    "len(c.corruption.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676ded8-b392-4491-9204-547c06e3ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
